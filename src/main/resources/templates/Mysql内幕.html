<html>
  <head>
	  <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <title>InnoDB内幕</title>
		<link href="/toc/style/github-bf51422f4bb36427d391e4b75a1daa083c2d840e.css" media="all" rel="stylesheet" type="text/css"/>
		<link href="/toc/css/zTreeStyle/zTreeStyle.css" media="all" rel="stylesheet" type="text/css"/>
  </head>
        <div id="allTree">
            <ul id="tree" class="ztree" >
            </ul>
        </div>

        <div id='readme' >
          	<article class='markdown-body'>
            	<h1 id="-mysql-">第一章: Mysql体系和存储引擎</h1>
<p>从图1-1可以发现，MySQL由以下几部分组成:</p>
<p>1.连接池组件<br>2.管理服务和工具组件<br>3.SQL接口组件<br>4.查询分析器组件<br>5.优化器组件<br>6.缓冲(Cache）组件<br>7.插件式存储引擎<br>8.物理文件</p>
<p>需要特别注意的是，存储引擎是基于表的，而不是数据库。</p>
<h2 id="1-1-mysql-">1.1 Mysql存储引擎</h2>
<p>对于开发人员来说，存储引擎对其是透明的，但了解各种存储引擎的区别对于开发人员来说也是有好处的。对于DBA来说，他们应该深刻地认识到MySQL数据库的核心在于存储引擎。</p>
<h3 id="1-1-1-innodb-">1.1.1 InnoDB引擎</h3>
<p>其设计目标主要面向在线事务处理(OLTP)的应用。</p>
<ul>
<li>支持行锁</li>
<li>支持事务</li>
<li>支持外键</li>
<li>支持类似Oracle的非锁定读(读取操作不会产生锁)</li>
</ul>
<p>InnoDB通过使用多版本并发控制（MVCC）来获得高并发性，并且实现了SQL标准的4种隔离级别，默认为REPEATABLE级别。同时，使用一种被称为next-keylocking的策略来避免幻读（phantom）现象的产生。除此之外，InnoDB储存引擎还提供了插入缓冲(insert buffer)、二次写(double write)、自适应哈希索引( adaptive hashindex)、预读（read ahead）等高性能和高可用的功能。</p>
<p>对于表中数据的存储，InnoDB存储引擎采用了聚集(clustered）的方式，因此每张表的存储都是按主键的顺序进行存放。如果没有显式地在表定义时指定主键，InnoDB存储引擎会为每一行生成一个6字节的ROWID，并以此作为主键。</p>
<h3 id="1-1-2-myisam-">1.1.2 MyISAM引擎</h3>
<p>其设计目标主要面向数据分析(OLAP)。</p>
<ul>
<li>不支持事务</li>
<li>支持表锁</li>
<li>支持全文索引 </li>
</ul>
<p>此外，MyISAM存储引擎的另一个与众不同的地方是它的缓冲池只缓存（cache）索引文件，而不缓冲数据文件，这点和大多数的数据库都非常不同。</p>
<h3 id="1-1-3-ndb-">1.1.3 NDB引擎</h3>
<p>NDB存储引擎是一个集群存储引擎，类似于Oracle的RAC集群，不过与OracleRACshare everything 架构不同的是，其结构是share nothing 的集群架构，因此能提供更高的可用性。NDB 的特点是数据全部放在内存中(从MySQL 5.1版本开始，可以将非索引数据放在磁盘上)，因此主键查找( primary key lookups）的速度极快，并且通过添加NDB数据存储节点（Data Node）可以线性地提高数据库性能，是高可用、高性能的集群系统。
关于NDB存储引擎，有一个问题值得注意，那就是NDB存储引擎的连接操作(JOIN)是在MySQL数据库层完成的，而不是在存储引擎层完成的。这意味着，复杂的连接操作需要巨大的网络开销，因此查询速度很慢。</p>
<h3 id="1-1-4-memory-">1.1.4 Memory引擎</h3>
<p>Memory存储引擎（之前称HEAP存储引擎）将表中的数据存放在内存中，如果数据库重启或发生崩溃，表中的数据都将消失。它适合用于存储临时数据的临时表，以及数据仓库中的纬度表。Memory存储引擎默认使用哈希索引。</p>
<p>使用上的限制：只支持表锁，并发性能较差，并且不支持TEXT 和 BLOB列类型。最重要的是，存储变长字段( varchar）时是按照定常字段(char)的方式进行的，因此会浪费内存。</p>
<p>此外有一点容易被忽视，MySQL数据库使用Memory存储引擎作为临时表来存放查询的中间结果集（intermediate result)。如果中间结果集大于Memory存储引擎表的容量设置，又或者中间结果含有TEXT 或BLOB列类型字段，则MySQL数据库会把其转换到MyISAM存储引擎表而存放到磁盘中。之前提到MyISAM不缓存数据文件，因此这时产生的临时表的性能对于查询会有损失。</p>
<h3 id="1-1-5-archive-">1.1.5 Archive引擎</h3>
<p>Archive存储引擎只支持INSERT和SELECT操作，从 MySQL 5.1开始支持索引。Archive存储引擎使用zlib算法将数据行（row）进行压缩后存储，压缩比一般可达1∶10。</p>
<ul>
<li>支持行锁</li>
<li>不支持事务</li>
</ul>
<p>Archive存储引擎非常适合存储归档数据，如日志信息。Archive存储引擎使用行锁来实现高并发的插人操作，但是其本身并不是事务安全的存储引擎，其设计目标主要是提供高速的插入和压缩功能。</p>
<p>此处有各个引擎差异图片
<br>
<br>
<br></p>
<h1 id="-inodb-">第二章 InoDB引擎</h1>
<h2 id="2-1-innodb-">2.1 InnoDB架构</h2>
<p>InnoDB存储引擎的架构。图2-1简单显示了InnoDB的存储引擎的体系架构，从图可见，InnoDB存储引擎有多个内存块，可以认为这些内存块组成了一个大的内存池，负责如下工作:<br></p>
<ul>
<li>维护所有进程/线程需要访问的多个内部数据结构。</li>
<li>缓存磁盘上的数据，方便快速地读取，同时在对磁盘文件的数据修改之前在这里缓存。</li>
<li>重做日志（redo log）缓冲。</li>
</ul>
<h3 id="2-1-1-">2.1.1 后台线程</h3>
<p>InnoDB存储引擎是多线程的模型，因此其后台有多个不同的后台线程，负责处理不同任务</p>
<ul>
<li>Master Thread： 是一个非常核心的后台线程，主要负责将缓冲池中的数据异步刷新到磁盘，保证数据的一致性，包括脏页的刷新等。</li>
<li>IO Thread： 在InnoDB存储引擎中大量使用了AIO (Async IO）来处理写IO请求，这样可以极大提高数据库的性能。而IO Thread的工作主要是负责这些IO请求的回调(call back)处理。</li>
<li>PurgeThread： 事务被提交后，其所使用的undolog可能不再需要，因此需要PurgeThread来回收已经使用并分配的undo页。</li>
</ul>
<h3 id="2-1-2-">2.1.2 内存</h3>
<p>在 InnoDB存储引擎中，缓冲池中页的大小默认为16KB</p>
<ul>
<li><p>缓冲池：<br>
缓冲池简单来说就是-一块内存区域，通过内存的速度来弥补磁盘速度较慢对数据库性能的影响。在数据库中进行读取页的操作，首先将从磁盘读到的页存放在缓冲池中。下一次再读相同的页时，首先判断该页是否在缓冲池中。若在缓冲池中，称该页在缓冲池中被命中，直接读取该页。否则，读取磁盘上的页。
<br>
<br>
对于数据库中页的修改操作，则首先修改在缓冲池中的页，然后再以一定的频率刷新到磁盘上。这里需要注意的是，页从缓冲池刷新回磁盘的操作并不是在每次页发生更新时触发，而是通过一种称为Checkpoint 的机制刷新回磁盘。这也是为了提高数据库的整体性能。
<br>
<br>
具体来看，缓冲池中缓存的数据页类型有﹔索引页、数据页、undo页、插入缓冲(insert buffer)、自适应哈希索引(adaptive hash index)、InnoDB存储的锁信息（lockinfo)、数据字典信息(data dictionary)等。不能简单地认为，缓冲池只是缓存索引页和数据页，它们只是占缓冲池很大的一部分而已。</p>
</li>
<li><p>LRU List、Free List和 Flush List：
<br>
通常来说，数据库中的缓冲池是通过LRU (最近最少使用）算法来进行管理的。即最频繁使用的页在LRU列表的前端，而最少使用的页在LRU列表的尾端。当缓冲池不能存放新读取到的页时，将首先释放LRU列表中尾端的页。
<br>
<br>
稍有不同的是InnoDB存储引擎对传统的LRU算法做了一些优化。在InnoDB的存储引擎中，LRU列表中还加人了midpoint位置。新读取到的页，虽然是最新访问的页，但并不是直接放入到LRU列表的首部，而是放入到LRU列表的midpoint位置。在默认配置下，该位置在LRU列表长度的5/8处。
<br>
<br>
那为什么不采用朴素的LRU算法，直接将读取的页放入到LRU列表的首部呢?这是因为若直接将读取到的页放入到LRU的首部，那么某些SQL操作可能会使缓冲池中的页被刷新出，从而影响缓冲池的效率。常见的这类操作为索引或数据的扫描操作。这类操作需要访问表中的许多页，甚至是全部的页，而这些页通常来说又仅在这次查询操作中需要，并不是活跃的热点数据。如果页被放入LRU列表的首部，那么非常可能将所需要的热点数据页从LRU列表中移除，而在下一次需要读取该页时，InnoDB存储引擎需要再次访问磁盘。
<br>
<br>
为了解决这个问题，InnoDB存储引擎引人了另一个参数来进一步管理LRU列表，这个参数是innodb_old_blocks_time，用于表示页读取到mid位置后需要等待多久才会被加人到LRU列表的热端。
<br>
<br>
在LRU列表中的页被修改后，称该页为脏页(dirty page)，即缓冲池中的页和磁盘上的页的数据产生了不一致。这时数据库会通过CHECKPOINT机制将脏页刷新回磁盘，而Flush列表中的页即为脏页列表。需要注意的是，脏页既存在于LRU列表中，也存在于Flush列表中。LRU列表用来管理缓冲池中页的可用性，Flush列表用来管理将页刷新回磁盘，二者互不影响。
<br>
<br>
LRU列表用来管理已经读取的页，但当数据库刚启动时，LRU列表是空的，即没有任何的页。这时页都存放在Free列表中。当需要从缓冲池中分页时，首先从Free列表中查找是否有可用的空闲页，若有则将该页从Free列表中删除，放入到LRU列表中。否则，根据LRU算法，淘汰LRU列表末尾的页，将该内存空间分配给新的页。</p>
</li>
<li><p>重做日志缓存(redo log buffer)：
<br>
InnoDB存储引擎首先将重做日志信息先放入到这个缓冲区，然后按一定频率将其刷新到重做日志文件。重做日志缓冲一般不需要设置得很大，因为一般情况下每一秒钟会将重做日志缓冲刷新到日志文件，因此用户只需要保证每秒产生的事务量在这个缓冲大小之内即可。默认为8MB。</p>
<ul>
<li>Master Thread每一秒将重做日志缓冲刷新到重做日志文件;</li>
<li>每个事务提交时会将重做日志缓冲刷新到重做日志文件;</li>
<li>当重做日志缓冲池剩余空间小于1/2时，重做日志缓冲刷新到重做日志文件。
<br>
<br></li>
</ul>
</li>
<li><p>额外的内存池：
<br>
额外的内存池通常被DBA忽略，他们认为该值并不十分重要，事实恰恰相反，该值同样十分重要。例如，分配了缓冲池，但是每个缓冲池中的帧缓冲(frame buffer）还有对应的缓冲控制对象( buffer control block)，这些对象记录了一些诸如LRU、锁、等待等信息，而这个对象的内存需要从额外内存池中申请。因此，在申请了很大的 InnoDB缓冲池时，也应考虑增加这个值。</p>
</li>
</ul>
<h2 id="2-2-checkpoint">2.2 CheckPoint</h2>
<p>倘若每次一个页发生变化，就将新页的版本刷新到磁盘，那么这个开销是非常大的。若热点数据集中在某几个页中，那么数据库的性能将变得非常差。同时，如果在从缓冲池将页的新版本刷新到磁盘时发生了宕机，那么数据就不能恢复了。为了避免发生数据丢失的问题，当前事务数据库系统普遍都采用了Write Ahead Log策略，即当事务提交时，先写重做日志，再修改页。当由于发生宕机而导致数据丢失时，通过重做日志来完成数据的恢复。这也是事务ACID中D (Durability持久性）的要求。</p>
<p>思考下面的场景，如果重做日志可以无限地增大，同时缓冲池也足够大，能够缓冲所有数据库的数据，那么是不需要将缓冲池中页的新版本刷新回磁盘。因为当发生宕机时，完全可以通过重做日志来恢复整个数据库系统中的数据到宕机发生的时刻。但是这需要两个前提条件:</p>
<ol>
<li>缓冲池可以缓存数据库中所有的数据。</li>
<li>重做日志可以无限增大。</li>
</ol>
<p>第一个条件在数据过大时难以实现，再来看第二个前提条件:重做日志可以无限增大。也许是可以的，但是这对成本的要求太高，同时不便于运维。DBA 或SA不能知道什么时候重做日志是否已经接近于磁盘可使用空间的阈值，并且要让存储设备支持可动态扩展也是需要一定的技巧。</p>
<p>好的，即使上述两个条件都满足，那么还有一个情况需要考虑:宕机后数据库的恢复时间。当数据库运行了几个月甚至几年时，这时发生宕机，重新应用重做日志的时间会非常久，此时恢复的代价也会非常大。</p>
<p>因此Checkpoint（检查点）技术的目的是解决以下几个问题:</p>
<ul>
<li>缩短数据库的恢复时间;</li>
<li>缓冲池不够用时，将脏页刷新到磁盘;</li>
<li>重做日志不可用时，刷新脏页。</li>
</ul>
<p>当数据库发生宕机时，数据库不需要重做所有的日志，因为Checkpoint之前的页都已经刷新回磁盘。故数据库只需对Checkpoint后的重做日志进行恢复。这样就大大缩短了恢复的时间。</p>
<p>此外，当缓冲池不够用时，根据LRU算法会溢出最近最少使用的页，若此页为脏页，那么需要强制执行Checkpoint，将脏页也就是页的<strong>新版本</strong>刷回磁盘。</p>
<p>重做日志出现不可用的情况是因为当前事务数据库系统对重做日志的设计都是循环使用的，并不是让其无限增大的，这从成本及管理上都是比较困难的。重做日志可以被重用的部分是指这些重做日志已经不再需要，即当数据库发生宕机时，数据库恢复操作不需要这部分的重做日志，因此这部分就可以被覆盖重用。若此时重做日志还需要使用，那么必须强制产生Checkpoint，将缓冲池中的页至少刷新到当前重做日志的位置。</p>
<p>对于InnoDB存储引擎而言，其是通过LSN (Log Sequence Number）来标记版本的。而LSN是8字节的数字，其单位是字节。每个页有LSN，重做日志中也有LSN,Checkpoint也有LSN。可以通过命令SHOW ENGINE INNODB STATUS来观察:</p>
<p>在InnoDB中有两种Checkpoint，分别为:</p>
<ol>
<li><p>Sharp Checkpoint
<br>
Sharp Checkpoint发生在数据库关闭时将所有的脏页都刷新回磁盘，这是默认的工作方式，但是若数据库在运行时也使用Sharp Checkpoint，那么数据库的可用性就会受到很大的影响。</p>
</li>
<li><p>Fuzzy Checkpoint
<br>
即只刷新一部分脏页，而不是刷新所有的脏页回磁盘。</p>
</li>
</ol>
<h2 id="2-3-lnnodb-">2.3 lnnoDB 关键特性</h2>
<p>lnnoDB 关键特性包括：</p>
<ul>
<li>插入缓冲( Insert Buffer)</li>
<li>两次写(Double Write）</li>
<li>自适应哈希索引（Adaptive Hash Index)</li>
<li>异步IO( Async IO)</li>
<li>刷新邻接页(Flush Neighbor Page)<h3 id="2-3-1-">2.3.1 插入缓冲</h3>
1.这个名字可能会让人认为插人缓冲是缓冲池中的一个组成部分。其实不然，InnoDB缓冲池中有Insert Buffer信息固然不错，但是Insert Buffer 和数据页一样，也是物理页的一个组成部分。</li>
</ul>
<p>在InnoDB存储引擎中，主键是行唯一的标识符。通常应用程序中行记录的插人顺序是按照主键递增的顺序进行插入的。因此，插入聚集索引(Primary Key）一般是顺序的，不需要磁盘的随机读取。例如主键为递增属性。</p>
<p><strong>注意</strong>：并不是所有的主键插入都是顺序的。若主键类是UUID这样的类，那么插入和辅助索引一样，同样是随机的。即使主键是自增类型，但是插入的是指定的值，而不是NULL值，那么同样可能导致插入并非连续的情况。</p>
<p>但是不可能每张表上只有一个聚集索引，更多情况下，一张表上有多个非聚集的辅助索引(secondary index)。比如，用户需要按照b这个字段进行查找，并且b这个字段不是唯一的。在这样的情况下产生了一个非聚集的且不是唯一的索引。在进行插入操作时，数据页的存放还是按主键a进行顺序存放的，但是对于非聚集索引叶子节点的插入不再是顺序的了，这时就需要离散地访问非聚集索引页，由于随机读取的存在而导致了插入操作性能下降。当然这并不是这个b字段上索引的错误，而是因为B+树的特性决定了非聚集索引插人的离散性。</p>
<p>需要注意的是，在某些情况下，辅助索引的插入依然是顺序的，或者说是比较顺序的，比如用户购买表中的时间字段。在通常情况下，用户购买时间是一个辅助索引，用来根据时间条件进行查询。但是在插入时却是根据时间的递增而插入的，因此插入也是“较为”顺序的。</p>
<p>InnoDB存储引擎开创性地设计了Insert Buffer，对于非聚集索引的插人或更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在，则直接插人﹔若不在，则先放入到一个Insert Buffer对象中，好似欺骗数据库这个非聚集的索引已经插到叶子节点，而实际并没有，只是存放在另一个位置。然后再以一定的频率和情况进行Insert Buffer 和辅助索引页子节点的 merge（合并〉操作，这时通常能将多个插入合并到一个操作中（因为在一个索引页中)，这就大大提高了对于非聚集索引插入性能。</p>
<p>然而Insert Buffer的使用需要同时满足以下两个条件:</p>
<ul>
<li>索引是辅助索引(secondary index);</li>
<li>索引不是唯一的</li>
</ul>
<p>不过考虑这样-种情况:应用程序进行大量的插入操作，这些都涉及了不唯一的非聚集索引，也就是使用了Insert Buffer。若此时MySQL数据库发生了宕机，这时势必有大量的Insert Buffer并没有合并到实际的非聚集索引中去。因此这时恢复可能需要很长的时间，在极端情况下甚至需要几个小时。</p>
<p>辅助索引不能是唯一的，因为在插入缓冲时，数据库并不去查找索引页来判断插入的记录的唯一性。如果去查找肯定又会有离散读取的情况发生，从而导致Insert Buffer失去了意义。</p>
<p>2.lnsert Buffer的内部实现</p>
<p>可能令绝大部分用户感到吃惊的是，Insert Buffer的数据结构是一棵B+树。在MySQL 4.1之前的版本中每张表有一棵Insert Buffer B+树。而在现在的版本中，全局只有一棵Insert Buffer B+树，负责对所有的表的辅助索引进行Insert Buffer。而这棵B+树存放在共享表空间中，默认也就是ibdatal中。因此，试图通过独立表空间ibd文件恢复表中数据时，往往会导致CHECK TABLE失败。这是因为表的辅助索引中的数据可能还在Insert Buffer中，也就是共享表空间中，所以通过ibd文件进行恢复后，还需要进行REPAIR TABLE操作来重建表上所有的辅助索引。</p>
<p>Insert Buffer是一棵B+树，因此其也由叶节点和非叶节点组成。非叶节点存放的是查询的search key（键值)，其构造如图2-3所示。</p>
<p>search key一共占用9个字节，其中space表示待插入记录所在表的表空间id，在InnoDB存储引擎中，每个表有一个唯一的space id，可以通过space id查询得知是哪张表。space占用4字节。marker占用1字节，它是用来兼容老版本的 Insert Buffer。offset表示页所在的偏移量，占用4字节。</p>
<p>当一个辅助索引要插入到页(space，offset）时，如果这个页不在缓冲池中，那么InnoDB存储引擎首先根据上述规则构造一个search key，接下来查询Insert Buffer 这棵B+树，然后再将这条记录插人到Insert Buffer B+树的叶子节点中。
对于插入到Insert Buffer B+树叶子节点的记录（如图2-4所示)，并不是直接将待插入的记录插入，而是需要根据如下的规则进行构造:</p>
<p>space、marker、page_no字段和之前非叶节点中的含义相同，一共占用9字节。第4个字段metadata占用4字节，其存储的内容如表2-2所示。
IBUF_REC_OFFSET_COUNT是保存两个字节的整数，用来排序每个记录进人Insert Buffer的顺序。因为从InnoDB1.0.x开始支持Change Buffer，所以这个值同样记录进入Insert Buffer的顺序。通过这个顺序回放（replay)才能得到记录的正确值。</p>
<p>因为启用Insert Buffer索引后，辅助索引页(space，page_no）中的记录可能被插人到Insert Buffer B+树中，所以为了保证每次Merge Insert Buffer页必须成功，还需要有一个特殊的页用来标记每个辅助索引页(space，page_no）的可用空间。这个页的类型为Insert Buffer Bitmap。
每个辅助索引页在Insert Buffer Bitmap页中占用4位（bit)，由表2-3中的三个部分组成。</p>
<ul>
<li><p>IBUF_BITMAP_FREE(2bit)：</p>
<ul>
<li>0表示无可用剩余空间</li>
<li>1表示剩余空间大于1/32页(512字节)</li>
<li>2表示剩余空间大于1/16页</li>
<li>3表示剩余空间大于1/8页</li>
</ul>
</li>
<li><p>IBUF_BITMAP_BUFFERED: 1表示该辅助索引页有记录被缓存在 Insert Buffer B+树中。</p>
</li>
<li><p>IBUF BITMAP IBUF: 1表示该页为Insert Buffer B+树的索引页</p>
</li>
</ul>
<p>4.Merge Insert Buffer</p>
<p>通过前面的小节读者应该已经知道了Insert/Change Buffer是一棵B+树。若需要实现插入记录的辅助索引页不在缓冲池中，那么需要将辅助索引记录首先插入到这棵B+树中。但是Insert Buffer 中的记录何时合并（merge）到真正的辅助索引中呢?</p>
<p>概括地说，Merge Insert Buffer的操作可能发生在以下几种情况下:</p>
<ul>
<li>辅助索引页被读取到缓冲池时;</li>
<li><p>Insert Buffer Bitmap页追踪到该辅助索引页已无可用空间时:
<br>
若插入辅助索引记录时检测到插入记录后可用空间会小于1/32页，则会强制进行一个合并操作，即强制读取辅助索引页，将Insert Buffer B+树中该页的记录及待插入的记录插人到辅助索引页中。这就是上述所说的第二种情况。</p>
</li>
<li><p>Master Thread。</p>
</li>
</ul>
<h3 id="2-3-2-">2.3.2 两次写</h3>
<p>如果说Insert Buffer带给InnoDB存储引擎的是性能上的提升，那么doublewrite（两次写）带给InnoDB存储引擎的是数据页的可靠性。</p>
<p>当发生数据库宕机时，可能InnoDB存储引擎正在写入某个页到表中，而这个页只写了一部分，比如16KB的页，只写了前4KB，之后就发生了宕机，这种情况被称为部分写失效(partial page write)。在 InnoDB存储引擎未使用doublewrite技术前，曾经出现过因为部分写失效而导致数据丢失的情况。</p>
<p>有经验的DBA也许会想，如果发生写失效，可以通过重做日志进行恢复。这是一个办法。但是必须清楚地认识到，重做日志中记录的是对页的物理操作，如偏移量800,写 &#39; aaaa&#39;记录。如果这个页本身已经发生了损坏，再对其进行重做是没有意义的。这就是说，在应用(apply）重做日志前，用户需要一个页的副本，当写入失效发生时，先通过页的副本来还原该页，再进行重做，这就是doublewrite。</p>
<p><strong>此处有图</strong> pdf54页</p>
<p>doublewrite由两部分组成，一-部分是内存中的doublewrite buffer，大小为2MB，另一部分是物理磁盘上共享表空间中连续的128个页，即2个区(extent)，大小同样为2MB。在对缓冲池的脏页进行刷新时，并不直接写磁盘，而是会通过memcpy函数将脏页先复制到内存中的doublewrite buffer，之后通过doublewrite buffer再分两次，每次1MB顺序地写入共享表空间的物理磁盘上，然后马上调用fsync函数，同步磁盘，避免缓冲写带来的问题。在这个过程中，因为doublewrite页是连续的，因此这个过程是顺序写的，开销并不是很大。在完成doublewrite页的写入后，再将doublewrite buffer中的页写入各个表空间文件中，此时的写入则是离散的。</p>
<h3 id="2-3-3-">2.3.3 自适应哈希</h3>
<p>哈希(hash）是一种非常快的查找方法，在一般情况下这种查找的时间复杂度为O(1)，即一般仅需要一次查找就能定位数据。而B+树的查找次数，取决于B+树的高度，在生产环境中，B+树的高度一般为3～4层，故需要3～4次的查询。</p>
<p>InnoDB存储引擎会监控对表上各索引页的查询。如果观察到建立哈希索引可以带来速度提升，则建立哈希索引，称之为自适应哈希索引(Adaptive Hash Index，AHI)。AHI是通过缓冲池的B+树页构造而来，因此建立的速度很快，而且不需要对整张表构建哈希索引。InnoDB存储引擎会自动根据访问的频率和模式来自动地为某些热点页建立哈希索引。</p>
<p>AHI有一个要求，即对这个页的连续访问模式必须是一样的。访问模式一样指的是查询的条件一样，若交替两种查询，那么InonDB存储引擎不会对该页构造AHI。此外AHI还有如下的要求:</p>
<ul>
<li>以该模式访问了100次</li>
<li>页通过该模式访问了N次，其中N=页中记录*1/16</li>
</ul>
<p>AHI是由InnoDB存储引擎控制的,默认开启。</p>
<h3 id="2-3-4-io">2.3.4 异步IO</h3>
<p>为了提高磁盘操作性能，当前的数据库系统都采用异步IO (Asynchronous IO,AIO)的方式来处理磁盘操作。InnoDB存储引擎亦是如此。</p>
<p>与AIO对应的是Sync I0，即每进行一次IO操作，需要等待此次操作结束才能继续接下来的操作。用户可以在发出一个IO请求后立即再发出另一个IO请求，当全部IO请求发送完毕后，等待所有IO操作的完成，这就是AIO。
AIO的另一个优势是可以进行IO Merge操作，也就是将多个IO合并为1个IO，这样可以提高IOPS的性能。例如用户需要访问页的(space，page_no）为:(8，6)、(8，7)，(8，8)
每个页的大小为16KB，那么同步IO需要进行3次IO操作。而AIO会判断到这三个页是连续的(显然可以通过(space，page_no）得知)。因此AIO底层会发送一个IO请求，从（8，6）开始，读取48KB的页。</p>
<h3 id="2-3-5-">2.3.5 刷新邻接页</h3>
<p>InnoDB存储引擎还提供了Flush Neighbor Page（刷新邻接页）的特性。其工作原理为﹔当刷新一个脏页时，InnoDB存储引擎会检测该页所在区（extent）的所有页，如果是脏页，那么一起进行刷新。这样做的好处显而易见，通过AIO可以将多个IO写入操作合并为一个IO操作，故该工作机制在传统机械磁盘下有着显著的优势。但是需要考虑到下面两个问题:</p>
<ul>
<li>是不是可能将不怎么脏的页进行了写人，而该页之后又会很快变成脏页?</li>
<li>固态硬盘有着较高的IOPS，是否还需要这个特性?</li>
</ul>
<p>为此，InnoDB存储引擎从1.2.x版本开始提供了参数innodb_flush_neighbors，用来控制是否启用该特性。对于传统机械硬盘建议启用该特性，而对于固态硬盘有着超高IOPS性能的磁盘，则建议将该参数设置为0，即关闭此特性。
<br>
<br>
<br></p>
<h1 id="-">第三章 文件</h1>
<ul>
<li>参数文件：告诉MySQL实例启动时在哪里可以找到数据库文件，并且指定某些初始化参数，这些参数定义了某种内存结构的大小等设置，还会介绍各种参数的类型。</li>
<li>日志文件:用来记录MySQL实例对某种条件做出响应时写入的文件，如错误日志文件、二进制日志文件、慢查询日志文件、查询日志文件等。</li>
<li>socket文件:当用UNIX域套接字方式进行连接时需要的文件。</li>
<li>pid文件:MySQL实例的进程ID文件。</li>
<li>MySQL表结构文件:用来存放MySQL表结构定义文件。</li>
<li>存储引擎文件:因为MySQL表存储引擎的关系，每个存储引擎都会有自己的文件来保存各种数据。这些存储引擎真正存储了记录和索引等数据。本章主要介绍与InnoDB有关的存储引擎文件。</li>
</ul>
<h2 id="3-1-">3.1 参数文件</h2>
<p>在默认情况下，MySQL实例会按照-定的顺序在指定的位置进行读取，用户只需通过命令mysql--help | grep my.cnf来寻找即可。</p>
<p>参数类型：</p>
<ul>
<li>动态（dynamic）参数 Mysql运行期间可以更改</li>
<li>静态（static）参数 运行时不可修改</li>
</ul>
<h2 id="3-2-">3.2 日志文件</h2>
<p>日志文件记录了影响MySQL数据库的各种类型活动。MySQL数据库中常见的日志文件有:</p>
<ul>
<li>错误日志（ error log)</li>
<li>二进制日志(binlog)</li>
<li>慢查询日志(slow query log)</li>
<li>查询日志(log)</li>
</ul>
<h3 id="3-2-1-">3.2.1 错误日志</h3>
<p>错误日志文件对MySQL的启动、运行、关闭过程进行了记录。MySQL DBA在遇到问题时应该首先查看该文件以便定位问题。该文件不仅记录了所有的错误信息，也记录―些警告信息或正确的信息。用户可以通过命令SHOW VARIABLES LIKE &#39;log_error&#39;来定位该文件。</p>
<p>MySQL数据库不能正常启动时，第一个必须查找的文件应该就是错误日志文件，该文件记录了错误信息，能很好地指导用户发现问题。</p>
<h3 id="3-2-2-">3.2.2 慢查询日志</h3>
<p>慢查询日志(slow log）可帮助定位可能存在问题的SQL语句，从而进行SQL语句层面的优化。例如，可以在 MySQL启动时设一个阈值，将运行时间超过该值的所有SQL语句都记录到慢查询日志文件中。DBA每天或每过一段时间对其进行检查，确认是否有SQL语句需要进行优化。该阈值可以通过参数long_query_time来设置，默认值为10，代表10秒。</p>
<p>这里有两点需要注意。首先，设置long_query_time这个阈值后，MySQL数据库会记录运行时间超过该值的所有SQL语句，但运行时间正好等于long_query_time的情况并不会被记录下。也就是说，在源代码中判断的是大于long_query_time，而非大于等于。其次，从 MySQL 5.1开始，long_query_time开始以微秒记录SQL语句运行的时间，之前仅用秒为单位记录。而这样可以更精确地记录SQL的运行时间，供DBA分析。对DBA来说，一条SQL语句运行0.5秒和0.05秒是非常不同的，前者可能已经进行了表扫，后面可能是进行了索引。</p>
<p>另一个和慢查询日志有关的参数是 log_queries_not_using_indexes，如果运行的SQL语句没有使用索引，则 MySQL数据库同样会将这条SQL语句记录到慢查询日志文件。首先确认打开了log_queries_not_using _indexes:</p>
<h3 id="3-2-3-">3.2.3 查询日志</h3>
<p>查询日志记录了所有对MySQL数据库请求的信息，无论这些请求是否得到了正确的执行。默认文件名为:主机名.log。如查看一个查询日志:</p>
<p>通过上述查询日志会发现，查询日志甚至记录了对Access denied的请求，即对于未能正确执行的SQL语句，查询日志也会进行记录。</p>
<h3 id="3-2-4-">3.2.4 二进制日志</h3>
<p>二进制日志(binary log）记录了对MySQL数据库执行更改的所有操作，但是不包括SELECT和SHOW这类操作，因为这类操作对数据本身并没有修改。然而，若操作本身并没有导致数据库发生变化，那么该操作可能也会写入二进制日志。例如:</p>
<p>从上述例子中可以看到，MySQL数据库首先进行UPDATE操作，从返回的结果看到Changed为0，这意味着该操作并没有导致数据库的变化。但是通过命令SHOWBINLOG EVENT可以看出在二进制日志中的确进行了记录。
如果用户想记录SELECT 和 SHOW操作，那只能使用查询日志，而不是二进制日志。此外，二进制日志还包括了执行数据库更改操作的时间等其他额外信息。总的来说，二进制日志主要有以下几种作用：</p>
<ul>
<li>恢复（recovery):某些数据的恢复需要二进制日志，例如，在一个数据库全备文件恢复后，用户可以通过二进制日志进行point-in-time的恢复。</li>
<li>复制（replication):其原理与恢复类似，通过复制和执行二进制日志使一台远程的MySQL数据库（一般称为slave或standby)与一台MySQL数据库（一般称为master或primary)进行实时同步。</li>
<li>审计(audit):用户可以通过二进制日志中的信息来进行审计，判断是否有对数据库进行注入的攻击。</li>
</ul>
<p>在默认情况下，二进制日志并不是在每次写的时候同步到磁盘（用户可以理解为缓冲写)。因此，当数据库所在操作系统发生宕机时，可能会有最后一部分数据没有写入二进制日志文件中，这会给恢复和复制带来问题。参数sync_binlog= [N】表示每写缓冲多少次就同步到磁盘。如果将N设为1，即 sync_binlog=1表示采用同步写磁盘的方式来写二进制日志，这时写操作不使用操作系统的缓冲来写二进制日志。</p>
<p>但是，即使将sync_binlog设为1，还是会有一种情况导致问题的发生。当使用InnoDB存储引擎时，在一个事务发出COMMIT动作之前，由于sync_binlog 为1，因此会将二进制日志立即写人磁盘。如果这时已经写入了二进制日志，但是提交还没有发生，并且此时发生了宕机，那么在MySQL数据库下次启动时，由于COMMIT操作并没有发生，这个事务会被回滚掉。但是二进制日志已经记录了该事务信息，不能被回滚。这个问题可以通过将参数innodb_support_xa设为1来解决，虽然innodb_support_xa与XA事务有关，但它同时也确保了二进制日志和 InnoDB存储引擎数据文件的同步。</p>
<p>binlog_format参数十分重要，它影响了记录二进制日志的格式。在MySQL 5.1版本之前，没有这个参数。所有二进制文件的格式都是基于SQL语句(statement）级别的。同时，对于复制是有一定要求的。如在主服务器运行rand、uuid等函数，又或者使用触发器等操作，这些都可能会导致主从服务器上表中数据的不一致(not sync)。另一个影响是，会发现InnoDB存储引擎的默认事务隔离级别是REPEATABLE READ。这其实也是因为二进制日志文件格式的关系，如果使用READ COMMITTED的事务隔离级别，会出现类似丢失更新的现象，从而出现主从数据库上的数据不一致。</p>
<p>MySQL 5.1开始引人了binlog_format参数，该参数可设的值有STATEMENT、ROW和MIXED</p>
<ul>
<li>STATEMENT: 记录SQL语句</li>
<li>ROW: 记录行更改情况，如果设置了binlog_format为 ROW，可以将InnoDB的事务隔离基本设为READCOMMITTED，以获得更好的并发性。</li>
<li>MIXED: 在MIXED格式下，MySQL默认采用STATEMENT格式进行二进制日志文件的记录，但是在一些情况下会使用ROW格式，可能的情况有:<ul>
<li>表的存储引擎为NDB，这时对表的 DML操作都会以ROW格式记录。</li>
<li>使用了UUID)、USERO)、CURRENT_USER()、FOUND_ROWSO、ROW_COUNTO等不确定函数。</li>
<li>使用了INSERT DELAY语句。</li>
<li>使用了用户定义函数（UDF)。</li>
<li>使用了临时表（ temporary table)。</li>
</ul>
</li>
</ul>
<p>在通常情况下，我们将参数binlog_format设置为ROW，这可以为数据库的恢复和复制带来更好的可靠性。但是不能忽略的一点是，这会带来二进制文件大小的增加，有些语句下的ROW格式可能需要更大的容量。比如我们有两张一样的表，大小都为100W，分别执行UPDATE操作，观察二进制日志大小的变化:</p>
<ul>
<li>STATEMENT: 增加200字节</li>
<li>ROW: 增加13MB</li>
</ul>
<p>上面的这个例子告诉我们，将参数binlog_format设置为ROW，会对磁盘空间要求有一定的增加。而由于复制是采用传输二进制日志方式实现的，因此复制的网络开销也有所增加。</p>
<h2 id="3-3-innodb-">3.3 InnoDB引擎文件</h2>
<h3 id="3-3-1-">3.3.1 表空间文件</h3>
<p>InnoDB采用将存储的数据按表空间( tablespace）进行存放的设计。在默认配置下会有一个初始大小为10MB，名为ibdatal的文件。该文件就是默认的表空间文件( tablespace file)，用户可以通过参数innodb_data_file_path对其进行设置。</p>
<p>设置innodb_data_file_path参数后，所有基于InnoDB存储引擎的表的数据都会记录到该共享表空间中。若设置了参数innodb_file_per_table，则用户可以将每个基于InnoDB存储引擎的表产生一个独立表空间。独立表空间的命名规则为:表名.ibd。通过这样的方式，用户不用将所有数据都存放于默认的表空间中。</p>
<p>需要注意的是，这些单独的表空间文件仅存储该表的数据、索引和插入缓冲BITMAP等信息，其余信息还是存放在默认的表空间中。</p>
<h3 id="3-3-2-redo-log-">3.3.2 重做日志文件（redo log）</h3>
<p>每个 InnoDB存储引擎至少有1个重做日志文件组(group)，每个文件组下至少有2个重做日志文件，如默认的 ib_logfile0和 ib_logfile1。为了得到更高的可靠性，用户可以设置多个的镜像日志组(mirrored log groups)，将不同的文件组放在不同的磁盘上，以此提高重做日志的高可用性。</p>
<p>在日志组中每个重做日志文件的大小一致，并以循环写入的方式运行。InnoDB存储引擎先写重做日志文件1，当达到文件的最后时会切换至重做日志文件2，再当重做日志文件⒉也被写满时，会再切换到重做日志文件1中。</p>
<p>重做日志文件不能设置得太大，如果设置得很大，在恢复时可能需要很长的时间;丹方面又不能设置得太小了，否则可能导致一个事务的日志需要多次切换重做日志文件。此外，重做日志文件太小会导致频繁地发生async checkpoint，导致性能的抖动。</p>
<p>也许有人会问，既然同样是记录事务日志，和之前介绍的二进制日志有什么区别?</p>
<ul>
<li>首先，二进制日志会记录所有与MySQL数据库有关的日志记录，包括InnoDB、MyISAM、Heap等其他存储引擎的日志。而InnoDB存储引擎的重做日志只记录有关该存储引擎本身的事务日志。</li>
<li>其次，记录的内容不同，无论用户将二进制日志文件记录的格式设为STATEMENT还是ROW，又或者是MIXED，其记录的都是关于一个事务的具体操作内容，即该日志是逻辑日志。而 InnoDB存储引擎的重做日志文件记录的是关于每个页(Page）的更改的物理情况。</li>
<li>此外，写人的时间也不同，二进制日志文件仅在事务提交前进行提交，即只写磁盘一次，不论这时该事务多大。而在事务进行的过程中，却不断有重做日志条目（redocntry〉被写入到重做日志文件中。</li>
</ul>
<p>重做日志非常的重要，用来记录InnoDB存储引擎的事务日志，也因为重做日志的存在，才使得InnoDB存储引擎可以提供可靠的事务。</p>
<h1 id="-">第四章 表</h1>
<h2 id="4-1-">4.1 索引组织表</h2>
<p>在InnoDB存储引擎中，表都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表(index organized table)。在 InnoDB存储引擎表中，每张表都有个主键(Primary Key)，如果在创建表时没有显式地定义主键，则InnoDB存储引擎会按如下方式选择或创建主键:</p>
<ul>
<li>首先判断表中是否有非空的唯一索引(Unique NOT NULL)，如果有，则该列即为主键。</li>
<li>如果不符合上述条件，InnoDB存储引擎自动创建一个6字节大小的指针。</li>
</ul>
<p>当表中有多个非空唯一索引时，InnoDB存储引擎将选择建表时第一个定义的非空唯一索引为主键。这里需要非常注意的是，主键的选择根据的是定义索引的顺序，而不是建表时列的顺序。</p>
<h2 id="4-2-innodb-">4.2 InnoDB存储结构</h2>
<p>从InnoDB存储引擎的逻辑存储结构看，所有数据都被逻辑地存放在一个空间中，称之为表空间(tablespace)。表空间又由段( segment)、区(extent)、页(page）组成。页在一些文档中有时也称为块(block)，InnoDB存储引擎的逻辑存储结构大致如图4-1所示。</p>
<h3 id="pdf93-"><strong>pdf93页</strong></h3>
<h3 id="4-2-1-">4.2.1 表空间</h3>
<p>表空间可以看做是InnoDB存储引擎逻辑结构的最高层，所有的数据都存放在表空间中。第3章中已经介绍了在默认情况下InnoDB存储引擎有一个共享表空间ibdata1,即所有数据都存放在这个表空间内。如果用户启用了参数innodb_file_per_table，则每张表内的数据可以单独放到一个表空间内。</p>
<p>如果启用了innodb_file_per_table 的参数，需要注意的是每张表的表空间内存放的只是数据、索引和插入缓冲Bitmap页，其他类的数据，如回滚（undo)信息，插人缓冲索引页、系统事务信息，二次写缓冲（Double write buffer）等还是存放在原来的共享表空间内。这同时也说明了另一个问题:即使在启用了参数innodb_file_per_table之后，共享表空间还是会不断地增加其大小。</p>
<h3 id="4-2-2-">4.2.2 段</h3>
<p>图4-1中显示了表空间是由各个段组成的，常见的段有数据段、索引段、回滚段等。因为前面已经介绍过了InnoDB存储引擎表是索引组织的（index organized)，因此数据即索引，索引即数据。那么数据段即为B+树的叶子节点（图4-1的Leaf node segment),索引段即为B+树的非索引节点（图4-1的Non-leaf node segment)。回滚段较为特殊，将会在后面的章节进行单独的介绍。</p>
<h3 id="4-2-3-">4.2.3 区</h3>
<p>区是由连续页组成的空间，在任何情况下每个区的大小都为1MB。为了保证区中页的连续性，InnoDB存储引擎一次从磁盘申请4～5个区。在默认情况下，InnoDB存储引擎页的大小为16KB，即一个区中一-共有64个连续的页。</p>
<p>InnoDB 1.2.x版本新增了参数innodb_page_size，通过该参数可以将默认页的大小设置为4K,8K，但是页中的数据库不是压缩。这时区中页的数量同样也为256、128。总之，不论页的大小怎么变化，区的大小总是为1M。</p>
<p>但是，这里还有这样一个问题:在用户启用了参数innodb_file_per_talbe后，创建的表默认大小是96KB。区中是64个连续的页，创建的表的大小至少是1MB才对啊?其实这是因为在每个段开始时，先用32个页大小的碎片页(fragment page）来存放数据，在使用完这些页之后才是64个连续页的申请。这样做的目的是，对于一些小表，或者是undo这类的段，可以在开始时申请较少的空间，节省磁盘容量的开销。</p>
<h3 id="4-2-4-">4.2.4 页</h3>
<p>同大多数数据库一样，InnoDB有页（Page）的概念（也可以称为块)，页是InnoDB磁盘管理的最小单位。在InnoDB存储引擎中，默认每个页的大小为16KB。而从InnoDB 1.2.x版本开始，可以通过参数innodb_page_size将页的大小设置为4K、8K、16K。若设置完成，则所有表中页的大小都为innodb_page_size，不可以对其再次进行修改。除非通过mysqldump导人和导出操作来产生新的库。</p>
<h3 id="4-2-5">4.2.5</h3>
<p>InnoDB存储引擎是面向列的〈row-oriented)，也就说数据是按行进行存放的。每个页存放的行记录也是有硬性定义的，最多允许存放16KB / 2 -200行的记录，即7992行记录。这里提到了row-oriented 的数据库，也就是说，存在有column-oriented 的数据库。MySQL infobright存储引擎就是按列来存放数据的，这对于数据仓库下的分析类SQL语句的执行及数据压缩非常有帮助。</p>
<h2 id="4-3-">4.3 行记录格式</h2>
<p>InnoDB存储引擎提供了Compact 和 Redundant两种格式来存放行记录数据，这也是目前使用最多的一种格式。Redundant格式是为兼容之前版本而保留的。</p>
<h3 id="4-3-1-">4.3.1 行溢出数据</h3>
<p>InnoDB存储引擎可以将一条记录中的某些数据存储在真正的数据页面之外。一般认为BLOB、LOB这类的大对象列类型的存储会把数据存放在数据页面之外。但是，这个理解有点偏差，BLOB可以不将数据放在溢出页面，而且即便是VARCHAR列数据类型，依然有可能被存放为行溢出数据。</p>
<p>首先对VARCHAR数据类型进行研究。很多DBA喜欢MySQL数据库提供的VARCHAR类型，因为相对于Oracle VARCHAR2最大存放4000字节，SQL Server最大存放8000字节，MySQL数据库的VARCHAR类型可以存放65535字节。但是，这是真的吗?真的可以存放65535字节吗?如果创建VARCHAR长度为65535的表，用户会得到下面的错误信息:</p>
<p>从错误消息可以看到InnoDB存储引擎并不支持65535长度的VARCHAR。这是因为还有别的开销，通过实际测试发现能存放VARCHAR类型的最大长度为65532。</p>
<p><strong>ps：</strong> 在我自己的数据库中报错最大为16383，这是因为使用UTF-8mb4字符集一个字符=4个字节，varchar(x)中x指的是字符个数，而不是字节个数。</p>
<p>此外需要注意的是，MySQL官方手册中定义的65535长度是指所有 VRCHAR列的长度总和，如果列的长度总和超出这个长度，依然无法创建，如下所示:</p>
<p>pdf112页</p>
<p>3个列长度总和是66000，因此InnoDB存储引擎再次报了同样的错误。即使能存放65532个字节，但是有没有想过，InnoDB存储引擎的页为16KB，即16384字节，怎么能存放65532字节呢?因此，在一般情况下，InnoDB存储引擎的数据都是存放在页类型为B-tree node 中。但是当发生行溢出时，数据存放在页类型为Uncompress BLOB页中。来看下面一个例子:</p>
<p>在上述例子中，首先创建了一个列a长度为65532的 VARCHAR类型表t，然后插入了列a长度为65 532的记录，接着看表空间文件，可以观察到实际存放的数据都在BLOB页中，那数据页中又存放了些什么内容呢?</p>
<p>可以看到，数据页面其实只保存了VARCHAR (65532)的前768字节的前缀(prefix）数据（这里都是a)，之后是偏移量，指向行溢出页，也就是前面用户看到的Uncompressed BLOB Page。因此，对于行溢出数据，其存放采用图4-4的方式。</p>
<p>那多长的VARCHAR是保存在单个数据页中的，从多长开始又会保存在BLOB页呢﹖可以这样进行思考:InnoDB存储引擎表是索引组织的，即 B+Tree 的结构，这样每个页中至少应该有两条行记录（否则失去了B+Tree的意义，变成链表了)。因此，如果页中只能存放下一条记录，那么InnoDB存储引擎会自动将行数据存放到溢出页中。考虑下面表的一种情况:</p>
<p>表t变长字段列a的长度为9000，故能存放在一个数据中，但是这并不能保证两条长度为9000的记录都能存放在一个页中。此时查看，可知行数据存放在BLOB页中。</p>
<p>但是，如果可以在一个页中至少放入两行数据，那 VARCHAR类型的行数据就不会存放到BLOB页中去。经过多次试验测试，发现这个阈值的长度为8098。如用户建立一个列为varchar ( 8098)的表，然后插入2条记录,则不在BLOB中。</p>
<p>另一个问题是，对于TEXT 或BLOB的数据类型，用户总是以为它们是存放在Uncompressed BLOB Page中的，其实这也是不准确的。是放在数据页中还是BLOB页中，和前面讨论的VARCHAR一样，至少保证一个页能存放两条记录。</p>
<p>当然既然用户使用了BLOB列类型，一般不可能存放长度这么小的数据。因此在大多数的情况下BLOB的行数据还是会发生行溢出，实际数据保存在BLOB页中，数据页只保存数据的前768字节。</p>
<h3 id="4-3-2-char-">4.3.2 CHAR的行结构存储</h3>
<p>通常理解VARCHAR是存储变长长度的字符类型，CHAR是存储固定长度的字符类型。然而，值得注意的是之前给出的两个例子中的字符集都是单字节的latin1格式。从MySQL4.1版本开始,CHR(N)中的N指的是字符的长度，而不是之前版本的字节长度。也就是说在不同的字符集下，CHAR类型列内部存储的可能不是定长的数据。例如下面的这个示例:</p>
<p>在上述例子中，表j的字符集是GBK。用户分别插入了两个字符的数据&#39;ab’和·我们&#39;，然后查看所占字节，可得如下结果:</p>
<p>通过不同的CHAR_LENGTH和CHAR函数可以观察到:前两个记录&#39;ab&#39;和·我们·字符串的长度都是2。但是内部存储上&#39;ab&#39;占用2字节，而·我们’占用4字节。如果通过HEX函数查看内部十六进制的存储，可以看到:</p>
<p>可以看到对于字符串 &#39;ab&#39;，其内部存储为0x6162。而字符串·我们·为OxCED2C3C7。因此对于多字节的字符编码，CHAR类型不再代表固定长度的字符串了。例如，对于UTF-8下 CHAR（10）类型的列，其最小可以存储10字节的字符，而最大可以存储30字节的字符。因此，对于多字节字符编码的CHAR数据类型的存储，InnoDB存储引擎在内部将其视为变长字符类型。</p>
<p>因此可以认为在多字节字符集的情况下，CHAR 和VARCHAR的实际行存储基本是没有区别的。</p>
<h2 id="4-4-">4.4 页</h2>
<p>待定。。。。</p>
<h2 id="4-5-">4.5 约束</h2>
<h3 id="4-5-1-">4.5.1 数据完整性</h3>
<p>一般来说，数据完整性有以下三种形式:</p>
<ul>
<li>实体完整性保证表中有一个主键。在InnoDB存储引擎表中，用户可以通过定义Primary Key或 Unique Key约束来保证实体的完整性。用户还可以通过编写一个触发器来保证数据完整性。</li>
<li>域完整性保证数据每列的值满足特定的条件。在InnoDB存储引擎表中，域完整性可以通过以下几种途径来保证:<ul>
<li>选择合适的数据类型确保一个数据值满足特定条件。</li>
<li>外键(Foreign Key）约束。</li>
<li>编写触发器。</li>
<li>还可以考虑用DEFAULT约束作为强制域完整性的一个方面。</li>
</ul>
</li>
<li>参照完整性保证两张表之间的关系。InnoDB存储引擎支持外键，因此允许用户定义外键以强制参照完整性，也可以通过编写触发器以强制执行。</li>
</ul>
<h3 id="4-5-2-">4.5.2 约束和索引的区别</h3>
<p>在前面的小节中已经看到Primary Key和 Unique Key的约束，有人不禁会问:这不就是通常创建索引的方法吗?那约束和索引有什么区别呢?</p>
<p>的确，当用户创建了一个唯一索引就创建了一个唯一的约束。但是约束和索引的概念还是有所不同的，约束更是一个逻辑的概念，用来保证数据的完整性，而索引是一个数据结构，既有逻辑上的概念，在数据库中还代表着物理存储的方式。</p>
<h3 id="4-5-3-">4.5.3 对错误数据的约束</h3>
<p>在某些默认设置下，MySQL数据库允许非法的或不正确的数据的插入或更新，又或者可以在数据库内部将其转化为一个合法的值，如向 NOT NULL 的字段插人一个NULL值，MySQL数据库会将其更改为0再进行插人，因此数据库本身没有对数据的正确性进行约束。如果用户想通过约束对于数据库非法数据的插人或更新，即MySQL数据库提示报错而不是警告，那么用户必须设置参数sql_mode，用来严格审核输入的参数。</p>
<h3 id="4-5-4-enum-set-">4.5.4 ENUM和SET约束</h3>
<p>MySQL数据库不支持传统的CHECK约束，但是通过ENUM和SET类型可以解决部分这样的约束需求。例如表上有一个性别类型，规定域的范围只能是male或female,在这种情况下用户可以通过ENUM类型来进行约束。</p>
<h3 id="4-5-5-">4.5.5 触发器约束</h3>
<p>触发器的作用是在执行INSERT、DELETE 和UPDATE命令之前或之后自动调用SQL命令或存储过程。</p>
<p>最多可以为一个表建立6个触发器，即分别为INSERT、UPDATE、DELETE 的BEFORE 和 AFTER各定义一个。BEFORE 和AFTER代表触发器发生的时间，表示是在每行操作的之前发生还是之后发生。</p>
<p>假设有张用户消费表，每次用户购买一样物品后其金额都是减的，若这时有“不怀好意”的用户做了类似减去一个负值的操作，这样用户的钱没减少反而会不断增加。</p>
<p>上述例子首先创建了一张表usercash_err_log来记录错误数值更新的日志，然后创建了进行约束操作的触发器tgr_usercash_update，其类型为BEFORE。触发器首先判断新、旧值之间的差值，在正常情况下消费总是减的，新值应该总是小于原来的值，因此大于原值的数据被判断为非法的输人，将cash值设定为原来的值，并将非法的数据更新插入表uscrcash_err_log。</p>
<h2 id="4-6-">4.6 视图</h2>
<p>在MySQL数据库中，视图（View）是一个命名的虚表，它由一个SQL查询来定义，可以当做表使用。与持久表(permanent table）不同的是，视图中的数据没有实际的物理存储。</p>
<h3 id="4-6-1-">4.6.1 视图的作用</h3>
<p>视图在数据库中发挥着重要的作用。视图的主要用途之一是被用做-个抽象装置，特别是对于一些应用程序，程序本身不需要关心基表(base table）的结构，只需要按照视图定义来取数据或更新数据，因此，视图同时在一定程度上起到一个安全层的作用。</p>
<p>虽然视图是基于基表的一个虚拟表，但是用户可以对某些视图进行更新操作，其本质就是通过视图的定义来更新基本表。一般称可以进行更新操作的视图为可更新视图。</p>
<ul>
<li><p>视图的DML操作对基表是有影响的，视图的insert,update,delete相关的基表也会被insert,update,delete</p>
</li>
<li><p>Drop视图对基表没有影响，删除基表后视图会没有数据，因为视图是不包含数据的（物化视图除外）。</p>
</li>
</ul>
<h3 id="4-6-2-">4.6.2 物化视图</h3>
<p>Oracle数据库支持物化视图——该视图不是基于基表的虚表，而是根据基表实际存在的实表，即物化视图的数据存储在非易失的存储设备上。物化视图可以用于预先计算并保存多表的链接（JOIN）或聚集（GROUP BY)等耗时较多的SQL操作结果。这样，在执行复杂查询时，就可以避免进行这些耗时的操作，从而快速得到结果。</p>
<p>MySQL数据库本身并不支持物化视图，换句话说，MySQL数据库中的视图总是虚拟的。但是用户可以通过一些机制来实现物化视图的功能。例如要创建一个ONDEMAND的物化视图还是比较简单的，用户只需定时把数据导人到另一张表。</p>
<h2 id="4-7-">4.7 分区表</h2>
<h3 id="4-7-1-">4.7.1 分区概述</h3>
<p>分区功能并不是在存储引擎层完成的，因此不是只有InnoDB存储引擎支持分区，常见的存储引擎MyISAM、NDB等都支持。但也并不是所有的存储引擎都支持，如CSV、FEDORATED、MERGE等就不支持。在使用分区功能前，应该对选择的存储引擎对分区的支持有所了解。</p>
<p>MySQL数据库支持的分区类型为水平分区，并不支持垂直分区。此外，MySQL数据库的分区是局部分区索引，一个分区中既存放了数据又存放了索引。而全局分区是指，数据存放在各个分区中，但是所有数据的索引放在一个对象中。</p>
<ul>
<li>水平分区，指将同一表中不同行的记录分配到不同的物理文件中。</li>
<li>垂直分区，指将同一表中不同列的记录分配到不同的物理文件中。</li>
</ul>
<p>大多数DBA会有这样一个误区:只要启用了分区，数据库就会运行得更快。这个结论是存在很多问题的。分区可能会给某些SQL语句性能带来提高,但是分区主要用于数据库高可用性的管理。</p>
<p>当前MySQL数据库支持以下几种类型的分区：</p>
<ul>
<li>RANGE分区:行数据基于属于一个给定连续区间的列值被放入分区。</li>
<li>LIST分区:和RANGE分区类似，只是LIST分区面向的是离散的值。</li>
<li>HASH分区:根据用户自定义的表达式的返回值来进行分区，返回值不能为负数。</li>
<li>KEY分区:根据 MySQL数据库提供的哈希函数来进行分区。</li>
</ul>
<p>不论创建何种类型的分区，如果表中存在主键或唯一索引时，分区列必须是唯-索引的一个组成部分。</p>
<p>唯一索引可以是允许NULL值的，并且分区列只要是唯一索引的一个组成部分，不需要整个唯一索引列都是分区列。</p>
<p>如果建表时没有指定主键，唯一索引，可以指定任何一个列为分区列。</p>
<h3 id="4-7-2-">4.7.2 分区类型</h3>
<p>1.RANGE分区</p>
<p>我们介绍的第一种分区类型是RANGE分区，也是最常用的一种分区类型。下面的CREATE TABLE语句创建了--个id列的区间分区表。当id小于10时，数据插人p0分区。当id大于等于10小于20时，数据插入p1分区。</p>
<p>因为表t根据列 id进行分区，所以数据是根据列id的值的范围存放在不同的物理文件中的。</p>
<p>对于表t，由于我们定义了分区，因此对于插入的值应该严格遵守分区的定义，当插人一个不在分区中定义的值时，MySQL数据库会抛出一个异常。我们向表t中插入30这个值报错。</p>
<p>对于上述问题，我们可以对分区添加一个MAXVALUE值的分区。MAXVALUE可以理解为正无穷，因此所有大于等于20且小于MAXVALUE的值别放入p2分区。</p>
<p>RANGE分区主要用于日期列的分区，例如对于销售类的表，可以根据年来分区存放销售记录。</p>
<p>这样创建的好处是，便于对sales这张表的管理。如果我们要删除2008年的数据，不需要执行DELETE FROM sales WHERE date&gt;=&#39;2008-01-01&#39; and date &lt;&#39;2009-01-01 &#39;，只需删除2008年数据所在的分区即可:</p>
<p>这样创建的另一个好处是可以加快某些查询操作，如果我们只需要查询2008年整年的销售额，可以这样:</p>
<p>通过EXPLAIN PARTITION命令我们可以发现，在上述语句中，SQL优化器只需要去搜索p2008这个分区，而不会去搜索所有的分区—-称为Partition Pruning(分区修剪)，故查询的速度得到了大幅度的提升。</p>
<p>2.List分区
LIST分区和RANGE分区非常相似，只是分区列的值是离散的，而非连续的。如:</p>
<pre><code class="lang-mysql">mysql&gt; CREATE TABLE t (
-&gt; a INT,
-&gt; b INT)ENGINE=INNODB-&gt;PARTITION BY LIST (b)(
-&gt;PARTITION po VALUES IN (1,3,5,7,9),
-&gt;PARTITION p1 VALUES IN (0,2,4,6,8)
-&gt; ) ;
Query oK,0 rows affected (0.26 sec)
</code></pre>
<p>如果插入的值不在分区的定义中，MySQL数据库同样会抛出异常。</p>
<p>另外，在用INSERT插人多个行数据的过程中遇到分区未定义的值时，MyISAM和InnoDB存储引擎的处理完全不同。MyISAM引擎会将之前的行数据都插人，但之后的数据不会被插人。而InnoDB存储引擎将其视为一个事务，因此没有任何数据插入。</p>
<p>3.哈希分区</p>
<p>HASH分区的目的是将数据均匀地分布到预先定义的各个分区中，保证各分区的数据数量大致都是一样的。在RANGE和LIST分区中，必须明确指定一个给定的列值或列值集合应该保存在哪个分区中﹔而在HASH分区中，MySQL自动完成这些工作，用户所要做的只是基于将要进行哈希分区的列值指定一个列值或表达式，以及指定被分区的表将要被分割成的分区数量。</p>
<p>要使用HASH分区来分割一个表，要在CREATE TABLE语句上添加一个“PARTITIONBY HASH (expr)”子句，其中“expr”是一个返回一个整数的表达式。它可以仅仅是字段类型为MySQL整型的列名。此外，用户很可能需要在后面再添加一个“PARTTTIONS nim&quot;子句，其中mum是一个非负的整数，它表示表将要被分割成分区的数量。如果没有包括一个PARTITIONS子句，那么分区的数量将默认为1。</p>
<p>下面的例子创建了一个HASH分区的表t，分区按日期列b进行:</p>
<pre><code class="lang-mysql">CREATETABLE t_hash (
a INT,
b DATETIME
)ENGINE=InnoDB
PARTITION BY HASH (YEAR(b))
PARTITIONs 4 ;
</code></pre>
<p>如果插入一个列b为2010-04-01的记录到表t_hash中，那么保存该条记录的分区如下:</p>
<p>MOD (YEAR ( &#39;2010-04-01&#39;) ,4)</p>
<p>=MOD (2010,4)</p>
<p>=2</p>
<p>因此记录会放入分区p2中。</p>
<p><strong>注意</strong>：即使是根据自增长主键进行的HASH分区也不能保证分区数据的均匀。因为插入的自增长ID并非总是连续的，如果该主键值因为某种原因被回滚了，则该值将不会再次被自动使用。</p>
<p>4.KEY分区</p>
<p>KEY分区和HASH分区相似，不同之处在于HASH分区使用用户定义的函数进行分区，KEY分区使用MySQL数据库提供的函数进行分区。对于NDB Cluster引擎，MySQL数据库使用MD5函数来分区﹔对于其他存储引擎，MySQL数据库使用其内部的哈希函数。</p>
<p>5.COLUMNS分区</p>
<p>在前面介绍的RANGE、LIST、HASH和KEY这四种分区中，分区的条件是:数据必须是整型(interger)，如果不是整型，那应该需要通过函数将其转化为整型，如YEAR()，TO_DAYS()，MONTH)等函数。MySQL5.5版本开始支持COLUMNS分区，可视为RANGE分区和LIST分区的一种进化。COLUMNS分区可以直接使用非整型的数据进行分区，分区根据类型直接比较而得，不需要转化为整型。此外，RANGECOLUMNS分区可以对多个列的值进行分区。</p>
<p>cOLUMNS分区支持以下的数据类型:</p>
<ul>
<li>所有的整型类型，如 INT、SMALLINT、TINYINT、BIGINT。FLOAT 和 DECIMAL则不予支持。</li>
<li>日期类型，如 DATE和 DATETIME。其余的日期类型不予支持。</li>
<li>字符串类型，如CHAR、VARCHAR、BINARY和VARBINARY。BLOB和 TEXT类型不予支持。</li>
</ul>
<p>对于日期类型的分区，我们不再需要YEAR()和TO_DAYS()函数了，而直接可以使用COLUMNS，如:</p>
<pre><code class="lang-mysql">CREATE TABLE t_columns_range (
a INT,
b DATETIME
)ENGINE=INNODB
PARTITION BY RANGE COLUMNS(B)(
PARTITIONpo VALUES LESS THAN ( &#39;2009-01-01 &#39;) ,
PARTITIONp1 VALUES LESS THAN( &#39;2010-01-01 &#39;)
) ;
</code></pre>
<p>同样可以直接使用字符串的分区:</p>
<pre><code class="lang-mysql">CREATETABLE customers_1 (
    first_name VARCHAR (25) ,
    last_name VARCHAR (25) ,
    street_1 VARCHAR (30) ,
    street_2 VARCHAR (30) ,
    city VARCHAR (15) ,
renewal DATE
)
PARTITION BY LIsT COLUMNs (city)
(PARTITION pRegion_1
    VALUES IN ( &#39;oskarshamn&#39;, &#39;Hogsby &#39; , &#39;Monsteras &#39; ) ,
PARTITION pRegion_2
    VALUES IN(&#39;Vimmerby&#39;, &#39;Hultsfred&#39;, &#39;vastervik&#39; ) ,
PARTITION pRegion_3
    VALUES IN( &#39;Nassjo&#39;,&#39;Eksjo&#39;, &#39;vetlanda &#39; ) ,
PARTITION pRegion_4
    VALUES IN(&#39; uppvidinge &#39;, &#39;Alvesta &#39;, &#39;vaxjo&#39;)
);
</code></pre>
<p>对于RANGE COLUMNS分区，可以使用多个列进行分区，如:</p>
<pre><code class="lang-mysql">CREATE TABLErcx (
    a INT,
    b INT,
    c CHAR (3) ,
    d INT
) Engine=InnoDB
PARTITION BY RANGE COLUMNS (a,d,c)(
PARTITION po VALUES LESS THAN (5,10,&#39; ggg &#39; ) ,
PARTITION p1 VALUES LESS THAN (10,20,&#39; mmmm &#39; ) ,
PARTITIONp2 VALUES LESS THAN﹒ (15,30,&#39;sss &#39; ) ,
PARTITION p3 VALUES LESSTHAN(MAXVALUE,MAXVALUE,MAXVALUE)
) ;
</code></pre>
<h3 id="4-7-3-">4.7.3 子分区</h3>
<p>子分区( subpartitioning）是在分区的基础上再进行分区，有时也称这种分区为复合分区(composite partitioning)。MySQL数据库允许在RANGE 和LIST的分区上再进行HASH或KEY的子分区，如:</p>
<h3 id="4-7-4-null-">4.7.4 分区中的NULL值</h3>
<p>MySQL数据库允许对NULL值做分区，但是处理的方法与其他数据库可能完全不同。MYSQL数据库的分区总是视NULL值视小于任何的一个非NULL值，这和MySQL数据库中处理NULL值的ORDER BY操作是一样的。因此对于不同的分区类型，MySQL数据库对于NULL值的处理也是各不相同。</p>
<p>对于RANGE分区，如果向分区列插入了NULL值，则 MySQL数据库会将该值放人最左边的分区。另外需要注意的是，如果删除pO这个分区，删除的将是小于10的记录，并且还有NULL值的记录，这点非常重要。</p>
<p>在LIST分区下要使用NULL值，则必须显式地指出哪个分区中放入NULL值，否则会报错。</p>
<p>HASH和KEY分区对于NULL 的处理方式和RANGE分区、LIST分区不一样。任何分区函数都会将含有NULL值的记录返回为0。如:</p>
<h3 id="4-7-5-">4.7.5 分区和性能</h3>
<p>我常听到开发人员说“对表做个分区”，然后数据库的查询就会快了。这是真的吗?实际上可能根本感觉不到查询速度的提升，甚至会发现查询速度急剧下降。因此，在合理使用分区之前，必须了解分区的使用环境。</p>
<p>数据库的应用分为两类:一类是OLTP（在线事务处理)，如 Blog、电子商务、网络游戏等;另-类是OLAP（在线分析处理)，如数据仓库、数据集市。在一个实际的应用环境中，可能既有OLTP的应用，也有OLAP的应用。如网络游戏中，玩家操作的游戏数据库应用就是OLTP的，但是游戏厂商可能需要对游戏产生的日志进行分析，通过分析得到的结果来更好地服务于游戏，预测玩家的行为等，而这却是OLAP的应用。
对于OLAP的应用，分区的确是可以很好地提高查询的性能，因为OLAP应用大多数查询需要频繁地扫描一张很大的表。假设有一张1亿行的表，其中有一个时间戳属性列。用户的查询需要从这张表中获取一年的数据。如果按时间戳进行分区，则只需要扫描相应的分区即可。这就是前面介绍的 Partition Pruning 技术。</p>
<p>然而对于OLTP的应用，分区应该非常小心。在这种应用下，通常不可能会获取一张大表中10%的数据，大部分都是通过索引返回几条记录即可。而根据B+树索引的原理可知，对于一张大表，一般的B+树需要2～3次的磁盘IO。因此B+树可以很好地完成操作，不需要分区的帮助，并且设计不好的分区会带来严重的性能问题。</p>
<p>我发现很多开发团队会认为含有1000W行的表是一张非常巨大的表，所以他们往往会选择采用分区，如对主键做10个HASH的分区，这样每个分区就只有100W的数据了，因此查询应该变得更快了，如 SELECT <em> FROM TABLE WHERE PK=@pk。但是有没有考虑过这样一种情况:100W和 1000W行的数据本身构成的B+树的层次都是一样的，可能都是2层。那么上述走主键分区的索引并不会带来性能的提高。好的，如果1000W的B+树的高度是3，100W的B+树的高度是2，那么上述按主键分区的索引可以避免1次IO，从而提高查询的效率。这没问题，但是这张表只有主键索引，没有任何其他的列需要查询的。如果还有类似如下的SQL语句:SELECT </em> FROM TABLEWHERE KEY=@key，这时对于KEY的查询需要扫描所有的10个分区，即使每个分区的查询开销为2次IO，则一共需要20次IO。而对于原来单表的设计，对于KEY的查询只需要2~3 次IO。</p>
<p>因此对于使用InnoDB存储引擎作为OLTP应用的表在使用分区时应该十分小心，设计时确认数据的访问模式，否则在OLTP应用下分区可能不仅不会带来查询速度的提高，反而可能会使你的应用执行得更慢。</p>
<h1 id="-">第五章 索引和算法</h1>
<h2 id="5-1-lnnodb-">5.1 lnnoDB存储引擎索引概述</h2>
<p>InnoDB存储引擎支持以下几种常见的索引:</p>
<ul>
<li>B+树索引</li>
<li>全文索引</li>
<li>哈希索引</li>
</ul>
<p>注意B+树中的B不是代表二叉(binary)，而是代表平衡（balance)，因为B+树是从最早的平衡二叉树演化而来，但是B+树不是一个二叉树。</p>
<p>另一个常常被DBA忽视的问题是:B+树索引并不能找到-个给定键值的具体行。B+树索引能找到的只是被查找数据行所在的页。然后数据库通过把页读入到内存，再在内存中进行查找，最后得到要查找的数据。</p>
<h2 id="5-2-">5.2 数据结构和算法</h2>
<p>B+树</p>
<p>这里，精简地对B+树做个介绍:B+树是一种平衡查找树。在B+树中，所有记录节点都是按键值的大小顺序存放在同--层的叶子节点上，由各叶子节点双向指针进行连接。</p>
<p>pdf187页</p>
<h2 id="5-3-b-">5.3 B+树索引</h2>
<p>B+索引在数据库中有一个特点是高扇出性，因此在数据库中，B+
树的高度一般都在2～4层，这也就是说查找某一键值的行记录时最多只需要2到4次IO，</p>
<p>数据库中的B+树索引可以分为聚集索引(clustered inex）和辅助索引(secondaryindex)°，但是不管是聚集还是辅助的索引，其内部都是B+树的，</p>
<h3 id="5-3-1-">5.3.1 聚集索引</h3>
<p>聚集索引（clustered index）就是按照每张表的主键构造一棵B+树，同时叶子节点中存放的即为整张表的行记录数据，也将聚集索引的叶子节点称为数据页。聚集索引的这个特性决定了索引组织表中数据也是索引的一部分。同B+树数据结构一样，每个数据页都通过一个双向链表来进行链接。</p>
<p>由于实际的数据页只能按照一棵B+树进行排序，因此每张表只能拥有一个聚集索引。在多数情况下，查询优化器倾向于采用聚集索引。因为聚集索引能够在B+树索引的叶子节点上直接找到数据。此外，由于定义了数据的逻辑顺序，聚集索引能够特别快地访问针对范围值的查询。查询优化器能够快速发现某一段范围的数据页需要扫描。</p>
<p>聚集索引的另一个好处是，它对于主键的排序查找和范围查找速度非常快。叶子节点的数据就是用户所要查询的数据。如用户需要查询一张注册用户的表，查询最后注册的10位用户，由于B+树索引是双向链表的，用户可以快速找到最后一个数据页，并取出10条记录，可以看到虽然使用ORDER BY对记录进行排序，但是在实际过程中并没有进行所谓的filesort操作，而这就是因为聚集索引的特点。</p>
<h3 id="5-3-2-">5.3.2 辅助索引</h3>
<p>对于辅助索引(Secondary Index，也称非聚集索引)，叶子节点并不包含行记录的全部数据。叶子节点除了包含键值以外，每个叶子节点中的索引行中还包含了一个书签( bookmark)。</p>
<p>辅助索引的叶子节点中包含了列c的值和主键的值。</p>
<p>当通过辅助索引来寻找数据时，遍历辅助索引获得指向主键索引的主键，然后再通过主键索引来找到一个完整的行记录。举例来说，如果在一棵高度为3的辅助索引树中查找数据，那需要对这棵辅助索引树遍历3次找到指定主键，如果聚集索引树的高度同样为3，那么还需要对聚集索引树进行3次查找，最终找到一个完整的行数据所在的页，因此一共需要6次逻辑IO访问以得到最终的一个数据页。</p>
<h2 id="5-4-cardinality-">5.4 Cardinality（基数）值</h2>
<h3 id="5-4-1-cardinality">5.4.1 什么是Cardinality</h3>
<p>并不是在所有的查询条件中出现的列都需要添加索引。对于什么时候添加B+树索引，一般的经验是，在访问表中很少一部分时使用B+树索引才有意义。对于性别字段。地区字段、类型字段，它们可取值的范围很小，称为低选择性。</p>
<p>怎样查看索引是否是高选择性的呢?可以通过SHOW INDEX结果中的列Cardinality来观察。Cardinality值非常关键，表示索引中不重复记录数量的预估值。同时需要注意的是，Cardinality是一个预估值，而不是一个准确值，基本上用户也不可能得到一个准确的值。在实际应用中，Cardinality/n_rows_in_table应尽可能地接近1。如果非常小，那么用户需要考虑是否还有必要创建这个索引。故在访问高选择性属性的字段并从表中取出很少一部分数据时，对这个字段添加B+树索引是非常有必要的。</p>
<h3 id="5-4-2-lnnodb-cardinality-">5.4.2 lnnoDB存储引擎的Cardinality 统计</h3>
<p>数据库是怎样来统计Cardinality信息的呢?因为MySQL 数据库中有各种不同的存储引擎，而每种存储引擎对于B+树索引的实现又各不相同，所以对Cardinality的统计是放在存储引擎层进行的。</p>
<p>此外需要考虑到的是，在生产环境中，索引的更新操作可能是非常频繁的。如果每次索引在发生操作时就对其进行Cardinality的统计，那么将会给数据库带来很大的负担。另外需要考虑的是，如果一张表的数据非常大，如一张表有50G的数据，那么统计一次Cardinality信息所需要的时间可能非常长。这在生产环境下，也是不能接受的。因此，数据库对于Cardinality 的统计都是通过采样(Sample）的方法来完成的。</p>
<p>在InnoDB存储引擎中，Cardinality统计信息的更新发生在两个操作中:INSERT和UPDATE。根据前面的叙述，不可能在每次发生INSERT和UPDATE时就去更新Cardinality信息，这样会增加数据库系统的负荷，同时对于大表的统计，时间上也不允许数据库这样去操作。因此，InnoDB存储引擎内部对更新Cardinality信息的策略为:</p>
<ul>
<li>表中1/16的数据已发生过变化。</li>
<li>stat_modified_counter&gt;2 000 000 000。</li>
</ul>
<p>第一种策略为自从上次统计Cardinality信息后，表中 1/16的数据已经发生过变化，这时需要更新Cardinality信息。第二种情况考虑的是，如果对表中某一行数据频繁地进行更新操作，这时表中的数据实际并没有增加，实际发生变化的还是这一行数据，则第一种更新策略就无法适用这这种情况。故在InnoDB存储引擎内部有一个计数器stat_modified_counter，用来表示发生变化的次数，当stat_modified_counter大于2 000 000000时，则同样需要更新Cardinality信息。</p>
<p>接着考虑InnoDB存储引擎内部是怎样来进行Cardinality信息的统计和更新操作的呢?同样是通过采样的方法。默认InnoDB存储引擎对8个叶子节点（Leaf Page）进行采用。采样的过程如下:</p>
<ol>
<li>取得B+树索引中叶子节点的数量，记为A。</li>
<li>随机取得B+树索引中的8个叶子节点。统计每个页不同记录的个数，即为P1，...，P8。
P2，…，P8。</li>
<li>根据采样信息给出Cardinality的预估值:Cardinality= (P1+P2+…+P8）*A/8。</li>
</ol>
<p>通过上述的说明可以发现，在InnoDB存储引擎中，Cardinality值是通过对8个叶子节点预估而得的，不是一个实际精确的值。再者，每次对Cardinality值的统计，都是通过随机取8个叶子节点得到的，这同时又暗示了另一-个Cardinality现象，即每次得到的Cardinality值可能是不同的。</p>
<p>当然，有一种情况可能使得用户每次观察到的索引Cardinality值都是一样的，那就是表足够小，表的叶子节点数小于或者等于8个。这时即使随机采样，也总是会采取到这些页，因此每次得到的Cardinality值是相同的。</p>
<h2 id="5-5-">5.5 索引的使用</h2>
<h3 id="5-5-1-b-">5.5.1不同应用中B+树索引的使用</h3>
<p>在了解了B+树索引的本质和实现后，下一个需要考虑的问题是怎样正确地使用B+树索引，这不是一个简单的问题。这里所总结的可能并不适用于所有的应用场合。我所能做的只是概括一个大概的方向。在实际的生产环境使用中，每个DBA和开发人员，还是需要根据自己的具体生产环境来使用索引，并观察索引使用的情况，判断是否需要添加索引。不要盲从任何人给你的经验意见，Think Different。</p>
<p>根据第1章的介绍，用户已经知道数据库中存在两种类型的应用，OLTP和 OLAP应用。在OLTP应用中，查询操作只从数据库中取得一小部分数据，一般可能都在10条记录以下，甚至在很多时候只取1条记录，如根据主键值来取得用户信息，根据订单号取得订单的详细信息，这都是典型OLTP应用的查询语句。在这种情况下，B+树索引建立后，对该索引的使用应该只是通过该索引取得表中少部分的数据。这时建立B+树索引才是有意义的，否则即使建立了，优化器也可能选择不使用索引。</p>
<p>对于OLAP应用，情况可能就稍显复杂了。不过概括来说，在OLAP应用中，都需要访问表中大量的数据，根据这些数据来产生查询的结果，这些查询多是面向分析的查询，目的是为决策者提供支持。如这个月每个用户的消费情况，销售额同比、环比增长的情况。因此在OLAP中索引的添加根据的应该是宏观的信息，而不是微观，因为最终要得到的结果是提供给决策者的。例如不需要在OLAP中对姓名字段进行索引，因为很少需要对单个用户进行查询。但是对于OLAP中的复杂查询，要涉及多张表之间的联接操作，因此索引的添加依然是有意义的。但是，如果联接操作使用的是Hash Join，那么索引可能又变得不是非常重要了，所以这需要DBA或开发人员认真并仔细地研究自己的应用。不过在OLAP应用中，通常会需要对时间字段进行索引，这是因为大多数统计需要根据时间维度来进行数据的筛选。</p>
<h3 id="5-5-2-">5.5.2 联合索引</h3>
<p>联合索引是指对表上的多个列进行索引。前面讨论的情况都是只对表上的一个列进行索引。联合索引的创建方法与单个索引创建的方法一样，不同之处仅在于有多个索引列。</p>
<p>讨论两个整型列组成的联合索引，假定两个键值的名称分别为a、b，如图5-22所示。</p>
<p>从图5-22可以观察到多个键值的B+树情况。其实和之前讨论的单个键值的B+树并没有什么不同，键值都是排序的，通过叶子节点可以逻辑上顺序地读出所有数据，就上面的例子来说，即（1，1)、(1，2)、(2，1)、(2，4)、(3，1)、(3，2)。数据按（a,b)的顺序进行了存放。</p>
<p>因此，对.于查询SELECT <em> FROM TABLE WHERE a=xxx and b=xxx，显然是可以使用(a，b）这个联合索引的。对于单个的a列查询SELECT </em>FROM TABLE WHEREa=xxx，也可以使用这个(a，b）索引。但对于b列的查询SELECT* FROM TABLEWHERE b=xxx，则不可以使用这棵B+树索引。可以发现叶子节点上的b值为1、2、1、4、1、2，显然不是排序的，因此对于b列的查询使用不到(a，b)的索引。</p>
<p>联合索引的第二个好处是已经对第二个键值进行了排序处理。例如，在很多情况下应用程序都需要查询某个用户的购物情况，并按照时间进行排序，最后取出最近三次的购买记录，这时使用联合索引可以避免多一次的排序操作，因为索引本身在叶子节点已经排序了。来看一个例子，首先根据如下代码来创建测试表buy_log:</p>
<pre><code class="lang-mysql">CREATE TABLE buy_log l
    userid INT UNSIGNED NOT NULL,
    buy_date DATE
)ENGINE=InnoDB;
INSERT INTO buy_log VALUES ( 1,&#39;2009-01-01 &#39; ) ;
INSERT INTO buy_log VALUES ( 2,&#39;2009-01-01 &#39;) ;
</code></pre>
<p>以上代码建立了两个索引来进行比较。两个索引都包含了userid字段。如果只对于userid进行查询，如:</p>
<pre><code class="lang-mysql">SELECT *FROM buy_log WHERE userid=2;
</code></pre>
<p>从图5-23中可以发现，possible_keys在这里有两个索引可供使用，分别是单个的userid索引和(userid，buy_date）的联合索引。但是优化器最终的选择是索引userid,因为该索引的叶子节点包含单个键值，所以理论上一个页能存放的记录应该更多。</p>
<p>接着假定要取出userid为1的最近3次的购买记录，其SQL语句如下，执行计划如图5-24所示。</p>
<pre><code class="lang-mysql">SELECT *FROM buy_log
WHERE userid=1 ORDER BY buy_date DESC LIMIT 3
</code></pre>
<p>同样的，对于上述的SQL语句既可以使用userid索引，也可以使用(userid，buy_date）索引。但是这次优化器使用了(userid，buy_date）的联合索引userid_2，因为在这个联合索引中buy_date已经排序好了。根据该联合索引取出数据，无须再对buy_date做一次额外的排序操作。</p>
<p>正如前面所介绍的那样，联合索引(a，b）其实是根据列a、b进行排序，因此下列语句可以直接使用联合索引得到结果:</p>
<pre><code class="lang-mysql">SELECT ... FROM TABLE WHERE a=xxx ORDER BY b
</code></pre>
<p>而对于联合索引(a,b， c）来说，下列语句同样可以直接通过联合索引得到结果:</p>
<pre><code class="lang-mysql">SELECT ... FROM TABLE WHERE a=xxx ORDER BY b
SELECT ... FROM TABLE WHEREa=xxx AND b=xxx ORDER BY c
</code></pre>
<p>但是对于下面的语句，联合索引不能直接得到结果，其还需要执行一次filesort 排序操作，因为索引(a，c）并未排序:</p>
<pre><code class="lang-mysql">SELECT ... FROM TABLE WHERE a=xxx ORDER BY c
</code></pre>
<h3 id="5-5-3-">5.5.3 覆盖索引</h3>
<p>InnoDB存储引擎支持覆盖索引(covering index，或称索引覆盖)，即从辅助索引中就可以得到查询的记录，而不需要查询聚集索引中的记录。使用覆盖索引的一个好处是辅助索引不包含整行记录的所有信息，故其大小要远小于聚集索引，因此可以减少大量的IO操作。例如根据索引列查主键</p>
<p>覆盖索引的另一个好处是对某些统计问题而言的。还是对于上一小节创建的表buy_log，要进行如下的查询:</p>
<pre><code class="lang-mysql">SELECT cOUNT ( * )FROM buy_log ;
</code></pre>
<p>InnoDB存储引擎并不会选择通过查询聚集索引来进行统计。由于buy_log 表上还有辅助索引，而辅助索引远小于聚集索引。</p>
<p>此外，在通常情况下，诸如（a，b）的联合索引，一般是不可以选择列b中所谓的查询条件。但是如果是统计操作，并且是覆盖索引的，则优化器会进行选择，如下述语句:</p>
<pre><code class="lang-mysql">SELECT cOUNT (* ) FROM buy_log
wHERE buy_date&gt;=&#39;2011-01-01&#39;AND buy_date&lt;&#39;2011-02-01&#39;
</code></pre>
<p>表buy_log有(userid，buy_date）的联合索引，这里只根据列b进行条件查询，一般情况下是不能进行该联合索引的，但是这句SQL查询是统计操作，并且可以利用到覆盖索引的信息，因此优化器会选择该联合索引。</p>
<h3 id="5-5-4-">5.5.4 优化器选择不使用索引的情况</h3>
<p>在某些情况下，当执行EXPLAIN命令进行SQL语句的分析时，会发现优化器并没有选择索引去查找数据，而是通过扫描聚集索引，也就是直接进行全表的扫描来得到数据。这种情况多发生于范围查找、JOIN链接操作等情况下。例如:</p>
<pre><code class="lang-mysql">SELECT * FROM orderdetails
WHERE orderid &gt; 10000 and orderid &lt; 102000;
</code></pre>
<p>可以看到表orderdetails有(OrderID，ProductID）的联合主键，此外还有对于列OrderID的单个索引。上述这句SQL显然是可以通过扫描OrderID上的索引进行数据的查找。然而通过EXPLAIN命令，用户会发现优化器并没有按照OrderID上的索引来查找数据。</p>
<p>这是为什么呢?原因在于用户要选取的数据是整行信息，而OrderID索引不能覆盖到我们要查询的信息，因此在对OrderID索引查询到指定数据后，还需要一次书签访问来查找整行数据的信息。虽然OrderID索引中数据是顺序存放的，但是再一次进行书签查找的数据则是无序的，因此变为了磁盘上的离散读操作。如果要求访问的数据量很小，则优化器还是会选择辅助索引，但是当访问的数据占整个表中数据的蛮大一部分时(-一般是20%左右)，优化器会选择通过聚集索引来查找数据。因为之前已经提到过，顺序读要远远快于离散读。</p>
<p>因此对于不能进行索引覆盖的情况，优化器选择辅助索引的情况是，通过辅助索引查找的数据是少量的。这是由当前传统机械硬盘的特性所决定的，即利用顺序读来替换随机读的查找。若用户使用的磁盘是固态硬盘，随机读操作非常快，同时有足够的自信来确认使用辅助索引可以带来更好的性能，那么可以使用关键字FORCE INDEX来强制使用某个索引。</p>
<h3 id="5-5-5-">5.5.5 索引提示</h3>
<p>MySQL数据库支持索引提示（INDEX HINT)，显式地告诉优化器使用哪个索引。个人总结以下两种情况可能需要用到INDEX HINT:</p>
<ul>
<li><p>MySQL数据库的优化器错误地选择了某个索引，导致SQL语句运行的很慢。这种情况在最新的MySQL数据库版本中非常非常的少见。优化器在绝大部分情况下工作得都非常有效和正确。这时有经验的DBA或开发人员可以强制优化器使用某个索引，以此来提高SQL运行的速度。</p>
</li>
<li><p>某SQL语句可以选择的索引非常多，这时优化器选择执行计划时间的开销可能会大于SQL语句本身。例如，优化器分析Range查询本身就是比较耗时的操作。这时DBA或开发人员分析最优的索引选择，通过Index Hint来强制使优化器不进行各个执行路径的成本分析，直接选择指定的索引来完成查询。</p>
</li>
</ul>
<p>USE INDEX只是告诉优化器可以选择该索引，实际上优化器还是会再根据自己的判断进行选择。而如果使用FORCE INDEX的索引提示，如:</p>
<p>可以看到，这时优化器的最终选择和用户指定的索引是一致的。因此，如果用户确定指定某个索引来完成查询，那么最可靠的是使用FORCE INDEX，而不是USEINDEX。</p>
<h3 id="5-5-6-multi-range-read-">5.5.6 Multi-Range Read优化</h3>
<p>MySQL5.6版本开始支持Multi-Range Read (MRR）优化。Multi-Range Read优化的目的就是为了减少磁盘的随机访问，并且将随机访问转化为较为顺序的数据访问，这对于IO-bound类型的SQL查询语句可带来性能极大的提升。Multi-Range Read优化可适用于range，ref，eq_ref类型的查询。</p>
<h3 id="5-5-7-index-condition-pushdown-icp-">5.5.7 Index Condition Pushdown (ICP)优化</h3>
<p>和Multi-Range Read一样，Index Condition Pushdown同样是MySQL 5.6开始支持的一种根据索引进行查询的优化方式。之前的MySQL数据库版本不支持Index ConditionPushdown，当进行索引查询时，首先根据索引来查找记录，然后再根据WHERE条件来过滤记录。在支持Index Condition Pushdown后，MySQL数据库会在取出索引的同时，判断是否可以进行WHERE条件的过滤，也就是将WHERE的部分过滤操作放在了存储引擎层。在某些查询下，可以大大减少上层SQL层对记录的索取（fetch)，从而提高数据库的整体性能。</p>
<h2 id="5-6-">5.6 哈希算法</h2>
<p>InnoDB存储引擎使用哈希算法来对字典进行查找，其冲突机制采用链表方式，哈希函数采用除法散列方式。即取余。</p>
<h2 id="5-7-">5.7 全文索引</h2>
<h3 id="5-7-1-">5.7.1 概述</h3>
<p>通过前面章节的介绍，已经知道B+树索引的特点，可以通过索引字段的前缀( prefix）进行查找。例如，对于下面的查询B+树索引是支持的:</p>
<pre><code class="lang-mysql">SELECT *FROM blog wHERE content like &#39;xxx%&#39;
</code></pre>
<p>上述SQL语句可以查询博客内容以xxx开头的文章，并且只要content添加了B+树索引，就能利用索引进行快速查询。然而实际这种查询不符合用户的要求，因为在更多的情况下，用户需要查询的是博客内容包含单词xxx的文章，即:</p>
<pre><code class="lang-mysql">SELECT * FROM blog WHERE content like &#39;%xxx号&#39;
</code></pre>
<p>根据B+树索引的特性，上述SQL语句即便添加了B+树索引也是需要进行索引的扫描来得到结果。类似这样的需求在互联网应用中还有很多。例如，搜索引擎需要根据用户输入的关键字进行全文查找，电子商务网站需要根据用户的查询条件，在可能需要在商品的详细介绍中进行查找，这些都不是B+树索引所能很好地完成的工作。
全文检索（Full-Text Search）是将存储于数据库中的整本书或整篇文章中的任意内容信息查找出来的技术。它可以根据需要获得全文中有关章、节、段、句、词等信息，也可以进行各种统计和分析。</p>
<p>从InnoDB 1.2.x版本开始，InnoDB存储引擎开始支持全文检索，其支持MyISAM存储引擎的全部功能，并且还支持其他的-些特性，这些将在后面的小节中进行介绍。</p>
<h3 id="5-7-2-">5.7.2 倒排索引</h3>
<p>全文检索通常使用倒排索引(inverted index）来实现。倒排索引同B+树索引一样，也是一种索引结构。它在辅助表( auxiliary table）中存储了单词与单词自身在一个或多个文档中所在位置之间的映射。这通常利用关联数组实现，其拥有两种表现形式:</p>
<ul>
<li>inverted file index，其表现形式为{单词，单词所在文档的ID}</li>
<li>full inverted index，其表现形式为{单词，(单词所在文档的ID，在具体文档中的位置)}</li>
</ul>
<p>pdf 233页</p>
<p>full inverted index还存储了单词所在的位置信息，如code这个单词出现在（1∶6),即文档1的第6个单词为code。相比之下，full inverted index占用更多的空间，但是能更好地定位数据，并扩充一些其他的搜索特性。</p>
<h3 id="5-7-3-lnnodb-">5.7.3 lnnoDB全文检索</h3>
<p>InnoDB存储引擎从1.2.x版本开始支持全文检索的技术，其采用full inverted index的方式。在InnoDB存储引擎中，将(Documentld，Position)视为一个“ilist”。因此在全文检索的表中，有两个列，一个是word字段，另一个是ilist字段，并且在word字段上有设有索引。此外，由于InnoDB存储引擎在ilist字段中存放了Position信息，故可以进行Proximity Search，而 MyISAM存储引擎不支持该特性。</p>
<p>正如之前所说的那样，倒排索引需要将word存放到一张表中，这个表称为Auxiliary Table（辅助表)。在InnoDB存储引擎中，为了提高全文检索的并行性能，共有6张Auxiliary Table，目前每张表根据word的 Latin编码进行分区。</p>
<p>Auxiliary Table是持久的表，存放于磁盘上。然而在InnoDB存储引擎的全文索引中，还有另外一个重要的概念FTS Index Cache(全文检索索引缓存)，其用来提高全文检索的性能。</p>
<p>FTS Index Cache是一个红黑树结构，其根据( word，ilist）进行排序。这意味着插入的数据已经更新了对应的表，但是对全文索引的更新可能在分词操作后还在FTS IndeCache 中，Auxiliary Table可能还没有更新。InnoDB存储引擎会批量对Auxiliary Table进行更新，而不是每次插人后更新一次Auxiliary Table。当对全文检索进行查询时，Auxiliary Table首先会将在FTS Index Cache中对应的word字段合并到Auxiliary Table中，然后再进行查询。这种merge操作非常类似之前介绍的Insert Buffer的功能，不同的是Insert Buffer是一个持久的对象，并且其是B+树的结构。然而FTS Index Cache的作用又和Insert Buffer是类似的，它提高了InnoDB存储引擎的性能，并且由于其根据红黑树排序后进行批量插人，其产生的Auxiliary Table相对较小。</p>
<p>InnoDB存储引擎允许用户查看指定倒排索引的Auxiliary Table中分词的信息，可以通过设置参数innodb_ft_aux_table来观察倒排索引的Auxiliary Table。</p>
<p>pdf234</p>
<p>stopword列表(stopword list）是本小节最后阐述的一个概念，其表示该列表中的word不需要对其进行索引分词操作。例如，对于the这个单词，由于其不具有具体的意义，因此将其视为stopword。InnoDB存储引擎有一张默认的stopword列表，其在information_schema架构下，表名为INNODB_FT_DEFAULT_STOPWORD，默认共有36个stopword。此外用户也可以通过参数innodb_ft_server_stopword_table来自定义stopword列表。</p>
<p>当前InnoDB存储引擎的全文检索还存在以下的限制:</p>
<ul>
<li>每张表只能有一个全文检索的索引。</li>
<li>由多列组合而成的全文检索的索引列必须使用相同的字符集与排序规则。</li>
<li>不支持没有单词界定符(delimiter）的语言，如中文、日语、韩语等。</li>
</ul>
<h3 id="5-7-4">5.7.4</h3>
<p>MySQL数据库通过MATCH()…AGAINST(语法支持全文检索的查询，MATCH 指定了需要被查询的列，AGAINST 指定了使用何种方法去进行查询。下面将对各种查询模式进行详细的介绍。</p>
<p>1.Natural Language</p>
<p>全文检索通过MATCH函数进行查询，默认采用Natural Language模式，其表示查询带有指定word 的文档。</p>
<pre><code class="lang-mysql">mysql&gt;SELECT *FROM fts_a
-&gt;WHERE MATCH (body)
-&gt;AGAINST ( &#39;Porridge&#39; IN NATURAL LANGUAGE MODE);
</code></pre>
<p>由于NATURAL LANGUAGE MODE是默认的全文检索查询模式，因此用户可以省略查询修饰符，即上述SQL语句可以写为:</p>
<pre><code class="lang-mysql">SELECT * FROM fts_a wHERE MATCH (body)AGAINST ( &#39;Porridge&#39; ) ;
</code></pre>
<p>在WHERE条件中使用MATCH 函数，查询返回的结果是根据相关性（Relevance）进行降序排序的，即相关性最高的结果放在第一位。相关性的值是一个非负的浮点数字，0表示没有任何的相关性。根据MySQL官方的文档可知，其相关性的计算依据以下四个条件:</p>
<ul>
<li>word是否在文档中出现。</li>
<li>word在文档中出现的次数。</li>
<li>word在索引列中的数量。</li>
<li>多少个文档包含该word。</li>
</ul>
<p>为了统计MATCH函数得到的结果数量，可以使用下列SQL语句:</p>
<pre><code class="lang-mysql">mysql&gt; SELECT count (*)
-&gt;FROM fts_a WHERE
-&gt;MATCH(body) AGAINST (&#39;Porridge&#39;IN NATURAL LANGUAGE MODE);
</code></pre>
<p>上述SQL语句也可以重写为:</p>
<pre><code class="lang-mysql">mysql&gt; SELECT
-&gt; COUNT  IF(MATCH(body)
-&gt;AGAINST (&#39;Porridge’IN NATURAL LANGUAGE MODE),1，NULL))
-&gt;As count
-&gt;FROM fts_a;
</code></pre>
<p>上述两句SQL语句虽然得到的逻辑结果是相同的，但是从内部运行来看，第二句SQL 的执行速度可能更快些。这是因为第--句SQL语句还需要进行相关性的排序统计，而在第二句SQL中是不需要的。</p>
<p>此外，用户可以通过SQL语句查看相关性。</p>
<p>对于InnoDB存储引擎的全文检索，还需要考虑以下的因素:</p>
<ul>
<li>查询的word在stopword列中，忽略该字符串的查询。</li>
<li>查询的word的字符长度是否在区间[innodb_ft_min_token_size，innodbft-max_token_size]内。</li>
</ul>
<p>如果词在stopword中，则不对该词进行查询。</p>
<p>可以看到，the虽然在文档1、5中出现，但由于其是stopword，故其相关性为0。</p>
<p>参数innodb_ft_min_token_size和 innodb_ft_max_token_size控制InnoDB存储引擎查询字符的长度，当长度小于innodb_ft_min_token_size，或者长度大于innodb_ft_max_token_size时，会忽略该词的搜索。在InnoDB存储引擎中，参数innodb_ft_min_token_size的默认值为3，参数innodb_ft_max_token_size的默认值为84。</p>
<p>2.Boolean</p>
<p>MySQL数据库允许使用IN BOOLEAN MODE修饰符来进行全文检索。当使用该修饰符时，查询字符串的前后字符会有特殊的含义，例如下面的语句要求查询有字符串Pease但没有hot的文档，其中＋和-分别表示这个单词必须出现，或者一定不存在。</p>
<pre><code class="lang-mysql">mysql&gt; SELECT *FROM fts_a
-&gt;WHERE MATCH (body)AGAINST( &#39;+Pease -hot&#39; IN BOOLEAN MODE)lG;
</code></pre>
<p>Boolean全文检索支持以下几种操作符:</p>
<ul>
<li>＋表示该word 必须存在。</li>
<li>-表示该word必须被排除。</li>
<li>(no operator）表示该word是可选的，但是如果出现，其相关性会更高</li>
<li>@distance表示查询的多个单词之间的距离是否在distance之内，distance的单位是字节。这种全文检索的查询也称为Proximity Search。如MATCH (body)AGAINST (&#39;&quot;Pease pot&quot;@30&#39; IN BOOLEAN MODE）表示字符串Pease和 pot之间的距离需在30字节内。</li>
<li><blockquote>
<p>表示出现该单词时增加相关性。</p>
</blockquote>
</li>
<li>&lt;表示出现该单词时降低相关性。</li>
<li>～表示允许出现该单词，但是出现时相关性为负（全文检索查询允许负相关性)。</li>
<li>*表示以该单词开头的单词，如 lik*，表示可以是lik、like，又或者likes。</li>
<li>&quot;表示短语。</li>
</ul>
<p>例子看pdf244页</p>
<p>3.Query Expansion</p>
<p>MySQL数据库还支持全文检索的扩展查询。这种查询通常在查询的关键词太短，用户需要implied knowledge（隐含知识）时进行。例如，对于单词database的查询，用户可能希望查询的不仅仅是包含database的文档，可能还指那些包含MySQL、Oracle、DB2、RDBMS的单词。而这时可以使用Query Expansion模式来开启全文检索的implied knowledge。</p>
<p>该查询分为两个阶段。</p>
<ul>
<li><p>第一阶段:根据搜索的单词进行全文索引查询。</p>
</li>
<li><p>第二阶段:根据第一阶段产生的分词再进行一次全文检索的查询。</p>
</li>
</ul>
<p>由于Query Expansion 的全文检索可能带来许多非相关性的查询，因此在使用时，用户可能需要非常谨慎。</p>
<h1 id="-">第六章 锁</h1>
<p>这一章将详细介绍InnoDB存储引擎对表中数据的锁定，同时分析InnoDB存储引擎会以怎样的粒度锁定数据。本章还对MyISAM、Oracle、sQL Server之间的锁进行了比较，主要是为了消除关于行级锁的一个“神话”:人们认为行级锁总会增加开销。实际上，只有当实现本身会增加开销时，行级锁才会增加开销。InnoDB存储引擎不需要锁升级，因为一个锁和多个锁的开销是相同的。</p>
<h2 id="6-1-">6.1什么是锁</h2>
<p>锁是数据库系统区别于文件系统的一个关键特性。锁机制用于管理对共享资源的并发访问。InnoDB存储引擎会在行级别上对表数据上锁，这固然不错。不过InnoDB存储引擎也会在数据库内部其他多个地方使用锁，从而允许对多种不同资源提供并发访问。例如，操作缓冲池中的LRU列表，删除、添加、移动LRU列表中的元素，为了保证一致性，必须有锁的介入。数据库系统使用锁是为了支持对共享资源进行并发访问，提供数据的完整性和一致性。</p>
<p>另一点需要理解的是，虽然现在数据库系统做得越来越类似，但是有多少种数据库，就可能有多少种锁的实现方法。</p>
<h2 id="6-2-lock-latch">6.2  lock与latch</h2>
<p>。在数据库中，lock 与latch都可以被称为“锁”。但是两者有着截然不同的含义，本章主要关注的是lock。</p>
<p>latch一般称为门锁(轻量级的锁)，因为其要求锁定的时间必须非常短。若持续的时间长，则应用的性能会非常差。在InnoDB存储引擎中，latch 又可以分为mutex （互斥量〉和rwlock（读写锁)。其目的是用来保证并发线程操作临界资源的正确性，并且通常没有死锁检测的机制。</p>
<p>lock 的对象是事务，用来锁定的是数据库中的对象，如表、页、行。并且一般lock的对象仅在事务commit或rollback后进行释放〈不同事务隔离级别释放的时间可能不同)。此外，lock，正如在大多数数据库中一样，是有死锁机制的。</p>
<h2 id="6-3-lnnodb-">6.3 lnnoDB存储引擎中的锁</h2>
<h3 id="6-3-1-">6.3.1锁的类型</h3>
<p>InnoDB存储引擎实现了如下两种标准的行级锁:</p>
<ul>
<li>共享锁(S Lock)，允许事务读一行数据。</li>
<li>排他锁(X Lock)，允许事务删除或更新一行数据。</li>
</ul>
<p>如果一个事务T1已经获得了行r的共享锁，那么另外的事务T2可以立即获得行r的共享锁，因为读取并没有改变行r的数据，称这种情况为锁兼容（Lock Compatible)。但若有其他的事务T3想获得行r的排他锁，则其必须等待事务T1、T2释放行r上的共享锁——这种情况称为锁不兼容。</p>
<p>X锁与任何的锁都不兼容，而S锁仅和S锁兼容。需要特别注意的是，S和X锁都是行锁，兼容是指对同一记录(row）锁的兼容性情况。</p>
<p>此外，InnoDB存储引擎支持多粒度( granular）锁定，这种锁定允许事务在行级上的锁和表级上的锁同时存在。为了支持在不同粒度上进行加锁操作，InnoDB存储引擎支持一种额外的锁方式，称之为意向锁（Intention Lock)。意向锁是将锁定的对象分为多个层次，意向锁意味着事务希望在更细粒度（fine granularity）上进行加锁，如图6-3所示。</p>
<p>若将上锁的对象看成一棵树，那么对最下层的对象上锁，也就是对最细粒度的对象进行上锁，那么首先需要对粗粒度的对象上锁。如果需要对页上的记录r进行上X锁，那么分别需要对数据库A、表、页上意向锁IX，最后对记录r上X锁。若其中任何一个部分导致等待，那么该操作需要等待粗粒度锁的完成。举例来说，在对记录r加X锁之前，已经有事务对表1进行了S表锁，那么表1上已存在S锁，之后事务需要对记录r在表1上加上IX，由于不兼容，所以该事务需要等待表锁操作的完成。</p>
<p>InnoDB存储引擎支持意向锁设计比较简练，其支持两种意向锁:</p>
<ol>
<li>意向共享锁(IS Lock)，事务想要获得一张表中某几行的共享锁</li>
<li>意向排他锁（IX Lock)，事务想要获得一张表中某几行的排他锁</li>
</ol>
<p>由于InnoDB存储引擎支持的是行级别的锁，因此意向锁其实不会阻塞除全表扫以外的任何请求。故表级意向锁与行级锁的兼容性如表6-4所示。</p>
<p>pdf266页</p>
<p>用户可以通过命令SHOW ENGINE INNODB STATUS命令来查看当前锁请求的信息。</p>
<p>...可以通过命令查看各个锁的情况... 待定...</p>
<h3 id="6-3-2-">6.3.2 一致性非锁定读</h3>
<p>一致性的非锁定读(consistent nonlocking read）是指InnoDB存储引擎通过行多版本控制(multi versioning)的方式来读取当前执行时间数据库中行的数据。如果读取的行正在执行DELETE或UPDATE操作，这时读取操作不会因此去等待行上锁的释放。相反地，InnoDB存储引擎会去读取行的一个快照数据。</p>
<p>快照数据是指该行的之前版本的数据，该实现是通过undo段来完成。而undo用来在事务中回滚数据，因此快照数据本身是没有额外的开销。此外，读取快照数据是不需要上锁的，因为没有事务需要对历史的数据进行修改操作。</p>
<p>快照数据其实就是当前行数据之前的历史版本，每行记录可能有多个版本。一个行记录可能有不止一个快照数据，一般称这种技术为行多版本技术。由此带来的并发控制，称之为多版本并发控制（Multi VersionConcurrency Control，MVCC)。</p>
<p>在事务隔离级别READ COMMITTED和 REPEATABLE READ (InnoDB存储引擎的默认事务隔离级别）下，InnoDB存储引擎使用非锁定的一致性读。然而，对于快照数据的定义却不相同。在READ COMMITTED事务隔离级别下，对于快照数据，非一致性读总是读取被锁定行的最新一份快照数据。而在REPEATABLE READ事务隔离级别下，对于快照数据，非一致性读总是读取事务开始时的行数据版本。</p>
<h3 id="6-3-3-">6.3.3一致性锁定读</h3>
<p>在前一小节中讲到，在默认配置下，即事务的隔离级别为REPEATABLE READ模式下，InnoDB存储引擎的SELECT操作使用一致性非锁定读。但是在某些情况下，用户需要显式地对数据库读取操作进行加锁以保证数据逻辑的一致性。而这要求数据库支持加锁语句，即使是对于SELECT的只读操作。InnoDB存储引擎对于SELECT语句专
持两种一致性的锁定读(locking read）操作:</p>
<ul>
<li>SELECT…FOR UPDATE</li>
<li>SELECT…LOCK IN SHARE MODE</li>
</ul>
<p>SELECT…FOR UPDATE对读取的行记录加一个X锁，其他事务不能对已锁定的行加上任何锁。SELECT…LOCK IN SHARE MODE对读取的行记录加一个S锁，其他事务可以向被锁定的行加S锁，但是如果加X锁，则会被阻塞。</p>
<p>对于一致性非锁定读，即使读取的行已被执行了SELECT…FOR UPDATE，也是可以进行读取的，这和之前讨论的情况一样。此外，SELECT…FOR UPDATE，SELECT…LOCK IN SHARE MODE必须在一个事务中，当事务提交了，锁也就释放了。因此在使用上述两句SELECT锁定语句时，务必加上BEGIN，START TRANSACTION或者SETAUTOCOMMIT=0。</p>
<h3 id="6-3-4-">6.3.4自增长与锁</h3>
<p>自增长在数据库中是非常常见的一种属性，也是很多DBA或开发人员首选的主键方式。在InnoDB存储引擎的内存结构中，对每个含有自增长值的表都有一个自增长计数器（〈auto-increment counter)。当对含有自增长的计数器的表进行插人操作时，这个计数器会被初始化，执行如下的语句来得到计数器的值:</p>
<pre><code class="lang-mysql">SELECT MAX (auto_inc_col)FROM t FOR UPDATE;
</code></pre>
<p>插入操作会依据这个自增长的计数器值加1赋予自增长列。这个实现方式称做AUTO-INC Locking。这种锁其实是采用-种特殊的表锁机制，为了提高插入的性能，锁不是在一个事务完成后才释放，而是在完成对自增长值插入的SQL语句后立即释放。</p>
<p>虽然AUTO-INC Locking从一定程度上提高了并发插入的效率，但还是存在一-些性能上的问题。首先，对于有自增长值的列的并发插入性能较差，事务必须等待前一个插入的完成（虽然不用等待事务的完成)。其次，对于INSERT…SELECT的大数据量的插人会影响插入的性能，因为另一个事务中的插人会被阻塞。</p>
<p>从 MySQL 5.1.22版本开始，InnoDB存储引擎中提供了一种轻量级<strong>互斥量</strong>的自增长实现机制，这种机制大大提高了自增长值插人的性能。二者可混合使用，详情见pdf263页</p>
<p>另外，在InnoDB存储引擎中，自增长值的列必须是索引，同时必须是索引的第缈个列。如果不是第一个列，则MySQL数据库会抛出异常，而MyISAM存储引擎没有这个问题。</p>
<h2 id="6-4-">6.4 锁的算法</h2>
<h3 id="6-4-1-3-">6.4.1行锁的3种算法</h3>
<p>InnoDB存储引擎有3种行锁的算法，其分别是:</p>
<ul>
<li>Record Lock:单个行记录上的锁</li>
<li>Gap Lock:间隙锁，锁定一个范围，但不包含记录本身</li>
<li>Next-Key Lock : Gap Lock+Record Lock，锁定一个范围，并且锁定记录本身</li>
</ul>
<p>Record Lock总是会去锁住索引记录，如果InnoDB存储引擎表在建立的时候没有设置任何一个索引，那么这时InnoDB存储引擎会使用隐式的主键来进行锁定。</p>
<p>Next-Key Lock是结合了Gap Lock 和 Record Lock 的一种锁定算法，在Next-KeyLock算法下，InnoDB对于行的查询都是采用这种锁定算法。例如一个索引有10，11，13和20这四个值，那么该索引可能被Next-Key Locking 的区间为:</p>
<p>(-∞,10]</p>
<p>(10,11]</p>
<p>(11,13]</p>
<p>( 13，20]</p>
<p>( 20,+∞)</p>
<p>采用Next-Key Lock 的锁定技术称为Next-Key Locking。其设计的目的是为了解决Phantom Problem，这将在下一小节中介绍。</p>
<p>然而，当查询的索引含有唯一属性时，InnoDB存储引擎会对Next-Key Lock进行优化，将其降级为Record Lock，即仅锁住索引本身，而不是范围。看下面的例子，首先根据如下代码创建测试表t:</p>
<p>表t共有1、2、5三个值。在上面的例子中，在会话A中首先对a=5进行X锁定。而由于a是主键且唯一，因此锁定的仅是5这个值，而不是(2，5)这个范围，这样在会话B中插人值4而不会阻塞，可以立即插入并返回。即锁定由Next-Key Lock算法降级为了Record Lock，从而提高应用的并发性。</p>
<p>正如前面所介绍的，Next-Key Lock降级为Record Lock仅在查询的列是唯一索引的情况下。若是辅助索引，则情况会完全不同。同样，首先根据如下代码创建测试表z</p>
<pre><code class="lang-mysql">CREATE TABLE z ( a INT, b INT,
    PRIMARY KEY(a),KEY(b)
);
INSERTINTO z SELECT 1,1;
INSERT INTO z SELECT 3,1;
INSERT INTO z SELECT 5,3;
INSERT INTO z SELECT 7,6;
INSERT INTO z SELECT 10,8;
</code></pre>
<p>表z的列b是辅助索引，若在会话A中执行下面的SQL语句:</p>
<pre><code class="lang-mysql">SELECT * FROM z WHERE b=3 FOR UPDATE
</code></pre>
<p>很明显，这时SQL语句通过索引列b进行查询，因此其使用传统的Next-KeyLocking 技术加锁，并且由于有两个索引，其需要分别进行锁定。对于聚集索引，其仅对列a等于5的索引加上Record Lock。而对于辅助索引，其加上的是Next-Key Lock,锁定的范围是(1，3)，特别需要注意的是，InnoDB存储引擎还会对辅助索引下一个键值
加上 gap lock，即还有一个辅助索引范围为(3，6)的锁。因此，若在新会话书中运行家面的SQL语句，都会被阻塞:</p>
<pre><code class="lang-mysql">SELECT *FROM z WHERE a = 5 LOCK IN SHARE MODE;
INSERT INTO z SELECT 4,2 ;
INSERTINTO z SELECT 6,5;
</code></pre>
<p>第一个SQL语句不能执行，因为在会话A中执行的SQL语句已经对聚集索引中列a =5的值加上X锁，因此执行会被阻塞。第二个SQL语句，主键插人4，没有问题，但是插人的辅助索引值2在锁定的范围(1，3)中，因此执行同样会被阻塞。第三个SQL语句，插人的主键6没有被锁定，5也不在范围(1，3)之间。但插入的值5在另一个锁定的范围(3，6)中，故同样需要等待。</p>
<p>最后需再次提醒的是，对于唯一键值的锁定，Next-Key Lock降级为Record Lock仅存在于查询所有的唯一索引列。若唯一索引由多个列组成，而查询仅是查找多个唯一索引列中的其中一个，那么查询其实是range类型查询，而不是point类型查询，故InnoDB存储引擎依然使用Next-Key Lock进行锁定。</p>
<h3 id="6-4-2-phantom-problem">6.4.2 解决Phantom Problem</h3>
<p>在默认的事务隔离级别下，即 REPEATABLE READ 下，InnoDB存储引擎采用Next-Key Locking机制来避免Phantom Problem(幻像问题)。
Phantom Problem是指在同一事务下，连续执行两次同样的SQL语句可能导致不同的结果，第二次的SQL语句可能会返回之前不存在的行。</p>
<p>此外，用户可以通过InnoDB存储引擎的Next-Key Locking 机制在应用层面实现唯一性的检查。例如:</p>
<pre><code class="lang-mysql">SELECT * FROM table WHERE col=xxx LOCK IN SHARE MODE;
If not found any row:
#unique for insert value
INSERT INTO table VALUES (.. . ) ;
</code></pre>
<p>如果用户通过索引查询一个值，并对该行加上一个SLock，那么即使查询的值不在，其锁定的也是-个范围，因此若没有返回任何行，那么新插人的值一定是唯一的。也许有读者会有疑问，如果在进行第一步SELECT…LOCK IN SHARE MODE操作时，有多个事务并发操作，那么这种唯一性检查机制是否存在问题。其实并不会，因为这时会导致死锁，只有一个事务的插人操作会成功，而其余的事务会抛出死锁的错误。</p>
<h2 id="6-5-">6.5 锁问题</h2>
<h3 id="6-5-1-">6.5.1 脏读</h3>
<p>脏数据是指未提交的数据，如果读到了脏数据，即一个事务可
以读到另外一个事务中未提交的数据，则显然违反了数据库的隔离性。</p>
<p>但是脏数据和之前所介绍的脏页完全是两种不同的概念。脏页指的是在缓冲池中已经被修改的页，但是还没有刷新到磁盘中，即数据库实例内存中的页和磁盘中的页的数据是不一致的，当然在刷新到磁盘之前，日志都已经被写入到了重做日志文件中。而所谓脏数据是指事务对缓冲池中行记录的修改，并且还没有被提交(commit)。</p>
<h3 id="6-5-2-">6.5.2 不可重复读</h3>
<p>不可重复读是指在一个事务内多次读取同一数据集合。在这个事务还没有结束时，另外一个事务也访问该同一数据集合，并做了一些DML操作。因此，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的情况，这种情况称为不可重复读。
不可重复读和脏读的区别是:脏读是读到未提交的数据，而不可重复读读到的却是已经提交的数据，但是其违反了数据库事务一致性的要求。</p>
<p>在InnoDB存储引擎中，通过使用Next-Key Lock算法来避免不可重复读的问题。在MySQL官方文档中将不可重复读的问题定义为Phantom Problem，即幻像问题。在 Next-Key Lock算法下，对于索引的扫描，不仅是锁住扫描到的索引，而且还锁住这些索引覆盖的范围(gap)。因此在这个范围内的插入都是不允许的。这样就避免了另外的事务在这个范围内插人数据导致的不可重复读的问题。</p>
<h3 id="6-5-3-">6.5.3丢失更新</h3>
<p>丢失更新是另一个锁导致的问题，简单来说其就是一个事务的更新操作会被另一个事务的更新操作所覆盖，从而导致数据的不一致。例如:</p>
<ol>
<li>事务T1将行记录r更新为v1，但是事务T1并未提交。</li>
<li>与此同时，事务T2将行记录r更新为v2，事务T2未提交。</li>
<li>事务T1提交。</li>
<li>事务T2提交。</li>
</ol>
<p>但是，在当前数据库的任何隔离级别下，都不会导致数据库理论意义上的丢失更新问题。这是因为，即使是READ UNCOMMITTED的事务隔离级别，对于行的DML操作，需要对行或其他粗粒度级别的对象加锁。因此在上述步骤2）中，事务T2并不能对行记录r进行更新操作，其会被阻塞，直到事务T1提交。</p>
<p>虽然数据库能阻止丢失更新问题的产生，但是在生产应用中还有另一个逻辑意义的丢失更新问题，而导致该问题的并不是因为数据库本身的问题。实际上，在所有多用户计算机系统环境下都有可能产生这个问题。简单地说来，出现下面的情况时，就会发生丢失更新:</p>
<ol>
<li>事务T1查询--行数据，放入本地内存，并显示给一个终端用户User1。</li>
<li>事务T2也查询该行数据，并将取得的数据显示给终端用户User2。</li>
<li>User1修改这行记录，更新数据库并提交。</li>
<li>User2修改这行记录，更新数据库并提交。</li>
</ol>
<p>显然，这个过程中用户User1的修改更新操作“丢失”了，而这可能会导致一多“恐怖”的结果。设想银行发生丢失更新现象，例如一个用户账号中有10 000元人民币，他用两个网上银行的客户端分别进行转账操作。第一次转账9000人民币，因为网络和数据的关系，这时需要等待。但是这时用户操作另一个网上银行客户端，转账1元，如果最终两笔操作都成功了，用户的账号余款是9999人民币，第一次转的9000人民币并没有得到更新，但是在转账的另一个账号却会收到这9000元，这导致的结果就是钱变多，而账不平。</p>
<p>要避免丢失更新发生，需要让事务在这种情况下的操作变成串行化，而不是并行的操作。即在上述四个步骤的1）中，对用户读取的记录加上一个排他X锁。同样，在步骤2）的操作过程中，用户同样也需要加一个排他X锁。通过这种方式，步骤2）就必须等待一步骤1）和步骤3）完成，最后完成步骤4)。</p>
<p>程序员可能在了解如何使用SELECT、INSERT、UPDATE、DELETE语句后就开始编写应用程序。因此，丢失更新是程序员最容易犯的错误，也是最不易发现的一个错误，因为这种现象只是随机的、零星出现的，不过其可能造成的后果却十分严重。</p>
<h2 id="6-6-">6.6 阻塞</h2>
<p>因为不同锁之间的兼容性关系，在有些时刻一个事务中的锁需要等待另一个事务中的锁释放它所占用的资源，这就是阻塞。阻塞并不是一件坏事，其是为了确保事务可以并发且正常地运行。</p>
<p>在InnoDB存储引擎中，参数innodb_lock_wait_timeout用来控制等待的时间（默认是50秒)，innodb_rollback_on_timeout用来设定是否在等待超时时对进行中的事务进行回滚操作（默认是OFF，代表不回滚)。参数innodb_lock_wait_timeout是动态的，可以在MySQL 数据库运行时进行调整:</p>
<p>需要牢记的是，在默认情况下InnoDB存储引擎不会回滚超时引发的错误异常。其实InnoDB存储引擎在大部分情况下都不会对异常进行回滚。如在一个会话中执行了如图操作</p>
<p>在会话A中开启了一个事务，在Next-Key Lock算法下锁定了小于4的所有记录(其实也锁定了4这个记录本身)。在另一个会话B中执行如下语句:</p>
<p>可以看到，在会话B中插人记录5是可以的，但是在插人记录3时，因为会话A中Next-Key Lock算法的关系，需要等待会话A中事务释放这个资源，所以等待后产生了超时。但是在超时后用户再进行SELECT操作时会发现，5这个记录依然存在:</p>
<p>这是因为这时会话B中的事务虽然抛出了异常，但是既没有进行COMMIT操作，也没有进行ROLLBACK。而这是十分危险的状态，因此用户必须判断是否需要COMMIT还是ROLLBACK，之后再进行下一步的操作。</p>
<h2 id="6-7-">6.7 死锁</h2>
<p>Oracle数据库中产生死锁的常见原因是没有对外键添加索引，而InnoDB存储引擎会自动对其进行添加，因而能够很好地避免了这种情况的发生。而人为删除外键上的索引，MySQL数据库会抛出一个异常:</p>
<p>InnoDB存储引擎并不会回滚大部分的错误异常，但是死锁除外。发现死锁后，InnoDB存储引擎会马上回滚一个事务，这点是需要注意的。因此如果在应用程序中捕获了1213这个错误，其实并不需要对其进行回滚。</p>
<h2 id="6-8-">6.8 锁升级</h2>
<p>锁升级（Lock Escalation）是指将当前锁的粒度降低。举例来说，数据库可以把一个表的1000个行锁升级为一个页锁，或者将页锁升级为表锁。如果在数据库的设计中认为锁是-种稀有资源，而且想避免锁的开销，那数据库中会频繁出现锁升级现象。
Microsoft sQL Server数据库的设计认为锁是一种稀有的资源，在适合的时候会自动地将行、键或分页锁升级为更粗粒度的表级锁。这种升级保护了系统资源，防止系统使用太多的内存来维护锁，在一定程度上提高了效率。</p>
<p>在 Microsoft sQL Server数据库中，由于锁是一种稀有的资源，因此锁升级会带来一定的效率提高。但是锁升级带来的一个问题却是因为锁粒度的降低而导致并发性能的降低。
InnoDB存储引擎不存在锁升级的问题。因为其不是根据每个记录来产生行锁的，相反，其根据每个事务访问的每个页对锁进行管理的，采用的是位图的方式。因此不管一个事务锁住页中一个记录还是多个记录，其开销通常都是一致的。</p>
<p>假设一张表有3 000 000个数据页，每个页大约有100条记录，那么总共有300 000 000条记录。若有一个事务执行全表更新的SQL语句，则需要对所有记录加X锁。若根据每行记录产生锁对象进行加锁，并且每个锁占用10字节，则仅对锁管理就需要差不多需要3GB的内存。而InnoDB存储引擎根据页进行加锁，并采用位图方式，假设每个页存储的锁信息占用30个字节，则锁对象仅需90MB 的内存。由此可见两者对于锁资源开销的差距之大。</p>
<h1 id="-">第七章 事务</h1>
<p>InnoDB存储引擎中的事务完全符合ACID 的特性。ACID是以下4个词的缩写:</p>
<ul>
<li>原子性（( atomicity)</li>
<li>一致性（consistency)</li>
<li>隔离性（ isolation)</li>
<li>持久性(durability)</li>
</ul>
<h2 id="7-1-">7.1认识事务</h2>
<h3 id="7-1-1-">7.1.1概述</h3>
<p>事务可由一条非常简单的SQL语句组成，也可以由一组复杂的SQL语句组成。</p>
<p><strong>A( Atomicity)，原子性</strong></p>
<p>原子性指整个数据库事务是不可分割的工.作单位。只有使事务中所有的数据库操作都执行成功，才算整个事务成功。事务中任何一个SQL语句执行失败，已经执行成功的sQL语句也必须撤销，数据库状态应该退回到执行事务前的状态。</p>
<p><strong>(consistency)，一致性</strong>。</p>
<p>一致性指事务将数据库从一种状态转变为下一种一致的状态。在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏。例如，在表中有一个字段为姓名，为唯一约束，即在表中姓名不能重复。如果一个事务对姓名字段进行了修改，但是在事务提交或事务操作发生回滚后，表中的姓名变得非唯一了，这就破坏了事务的一致性要求，即事务将数据库从一种状态变为了一种不一致的状态。因此，事务是一致性的单位，如果事务中某个动作失败了，系统可以自动撤销事务——-返回初抬化的状态。</p>
<p><strong>l(isolation)，隔离性</strong>。</p>
<p>隔离性还有其他的称呼，如并发控制(concurrency control)、可串行化(serializability)、锁(locking）等。事务的隔离性要求每个读写事务的对象对其他事务的操作对象能相互分离，即该事务提交前对其他事务都不可见，通常这使用锁来实现。</p>
<p><strong>D(durability)，持久性。</strong></p>
<p>事务一旦提交，其结果就是永久性的。即使发生宕机等故障，数据库也能将数据恢复。需要注意的是，只能从事务本身的角度来保证结果的永久性。例如，在事务提交后，所有的变化都是永久的。即使当数据库因为崩溃而需要恢复时，也能保证恢复后提交的数据都不会丢失。但若不是数据库本身发生故障，而是一些外部的原因，如RAID卡损坏、自然灾害等原因导致数据库发生问题，那么所有提交的数据可能都会丢失。因此持久性保证事务系统的高可靠性（High Reliability)，而不是高可用性（High Availability)。对于高可用性的实现，事务本身并不能保证，需要一些系统共同配合来完成。</p>
<h3 id="7-1-2-">7.1.2 分类</h3>
<p>从事务理论的角度来说，可以把事务分为以下几种类型:</p>
<ul>
<li>扁平事务(Flat Transactions)</li>
<li>带有保存点的扁平事务(Flat Transactions with Savepoints)</li>
<li>链事务（Chained Transactions)</li>
<li>嵌套事务（Nested Transactions&gt;分布式事务（Distributed Transactions)</li>
</ul>
<p><strong>扁平事务(Flat Transaction）</strong> 是事务类型中最简单的一种，但在实际生产环境中，这可能是使用最为频繁的事务。在扁平事务中，所有操作都处于同一层次，其由BEGINWORK开始，由COMMIT WORK或ROLLBACK WORK结束，其间的操作是原子的，要么都执行，要么都回滚。因此扁平事务是应用程序成为原子操作的基本组成模块。</p>
<p>扁平事务的主要限制是不能提交或者回滚事务的某一部分，或分几个步骤提交。下面给出一个扁平事务不足以支持的例子。例如用户在旅行网站上进行自己的旅行度假计</p>
<p><strong>带有保存点的扁平事务(Flat Transactions with Savepoint)</strong> 除了支持扁平事务支持的操作外，允许在事务执行过程中回滚到同一事务中较早的一个状态。这是因为某些事务可能在执行过程中出现的错误并不会导致所有的操作都无效，放弃整个事务不合乎要求，开销也太大。保存点(Savepoint）用来通知系统应该记住事务当前的状态，以便当之后发生错误时，事务能回到保存点当时的状态。</p>
<p>另一点需要注意的是，保存点在事务内部是递增的，这从图7-2中也能看出。有人可能会想，返回保存点2以后，下一个保存点可以为3，因为之前的工作都终止了。然而新的保存点编号为5，这意味着ROLLBACK不影响保存点的计数，并且单调递增的编号能保持事务执行的整个历史过程，包括在执行过程中想法的改变。</p>
<p>此外，当事务通过ROLLBACK WORK∶2命令发出部分回滚命令时，要记住事务并没有完全被回滚，只是回滚到了保存点2而已。这代表当前事务还是活跃的，如果想要完全回滚事务，还需要再执行命令ROLLBACK WORK。</p>
<p><strong>链事务(Chained Transaction）</strong> 可视为保存点模式的一种变种。带有保存点的扁平事务，当发生系统崩溃时，所有的保存点都将消失，因为其保存点是易失的（volatile),而非持久的( persistent)。这意味着当进行恢复时，事务需要从开始处重新执行，而不能从最近的一个保存点继续执行。
链事务的思想是﹔在提交一个事务时，释放不需要的数据对象，将必要的处理上下文隐式地传给下一个要开始的事务。注意，提交事务操作和开始下一个事务操作将合并为一个原子操作。这意味着下一个事务将看到上一个事务的结果，就好像在一个事务中</p>
<p><strong>链事务(Chained Transaction）</strong> 可视为保存点模式的-一-种变种。带有保存点的扁平事务，当发生系统崩溃时，所有的保存点都将消失，因为其保存点是易失的(volatile),而非持久的( persistent)。这意味着当进行恢复时，事务需要从开始处重新执行，而不能从最近的一个保存点继续执行。
链事务的思想是﹔在提交一个事务时，释放不需要的数据对象，将必要的处理上下文隐式地传给下一个要开始的事务。注意，提交事务操作和开始下一个事务操作将合并为一个原子操作。这意味着下一个事务将看到上一个事务的结果，就好像在一个事务中。</p>
<p>链事务与带有保存点的扁平事务不同的是，带有保存点的扁平事务能回滚到任意正确的保存点。而链事务中的回滚仅限于当前事务，即只能恢复到最近一个的保存点。对于锁的处理，两者也不相同。链事务在执行COMMIT后即释放了当前事务所持有的锁，而带有保存点的扁平事务不影响迄今为止所持有的锁。</p>
<p><strong>嵌套事务(Nested Transaction）</strong> 是一个层次结构框架。由一个顶层事务( top-level transaction）控制着各个层次的事务。顶层事务之下嵌套的事务被称为子事务( subtransaction)，其控制每一个局部的变换。嵌套事务的层次结构如图7-4所示。
....pdf291页</p>
<p>在Moss的理论中，实际的工作是交由叶子节点来完成的，即只有叶子节点的事务才能访问数据库、发送消息、获取其他类型的资源。而高层的事务仅负责逻辑控制，决定何时调用相关的子事务。即使一个系统不支持嵌套事务，用户也可以通过保存点技术来模拟嵌套事务，如图7-5所示。</p>
<p>但是用保存点技术来模拟嵌套事务在锁的持有方面还是与嵌套查询有些区别。当通过保存点技术来模拟嵌套事务时，用户无法选择哪些锁需要被子事务继承，哪些需要被父事务保留。这就是说，无论有多少个保存点，所有被锁住的对象都可以被得到和访问。而在嵌套查询中，不同的子事务在数据库对象上持有的锁是不同的。例如有一个父事务P，其持有对象X和Y的排他锁，现在要开始一个调用子事务P.，那么父事务P,可以不传递锁，也可以传递所有的锁，也可以只传递一个排他锁。</p>
<p>然而，如果系统支持在嵌套事务中并行地执行各个子事务，在这种情况下，采用保存点的扁平事务来模拟嵌套事务就不切实际了。这从另一个方面反映出，想要实现事务间的并行性，需要真正支持的嵌套事务。</p>
<p><strong>分布式事务(Distributed Transactions）</strong>
通常是一个在分布式环境下运行的扁平事务，因此需要根据数据所在位置访问网络中的不同节点。</p>
<p>假设一个用户在ATM机进行银行的转账操作，例如持卡人从招商银行的储蓄卡转账10 000元到工商银行的储蓄卡。在这种情况下，可以将ATM机视为节点A，招商银行的后台数据库视为节点B，工商银行的后台数据库视为C，这个转账的操作可分解为以下的步骤:</p>
<ol>
<li>节点A发出转账命令。</li>
<li>节点B执行储蓄卡中的余额值减去10 000。</li>
<li>节点C执行储蓄卡中的余额值加上 10 000。</li>
<li>节点A通知用户操作完成或者节点A通知用户操作失败。</li>
</ol>
<p>这里需要使用分布式事务，因为节点A不能通过调用一台数据库就完成任务。其需要访问网络中两个节点的数据库，而在每个节点的数据库执行的事务操作又都是扁平的。对于分布式事务，其同样需要满足ACID特性，要么都发生，要么都失效。对于上述的例子，如果2)、3）步中任何一个操作失败，都会导致整个分布式事务回滚。若非这样，结果会非常可怕。</p>
<p>对于InnoDB存储引擎来说，其支持扁平事务、带有保存点的事务、链事务、分布式事务。对于嵌套事务，其并不原生支持，因此，对有并行事务需求的用户来说，MySQL数据库或InnoDB存储引擎就显得无能为力了。然而用户仍可以通过带有保存点的事务来模拟串行的嵌套事务。</p>
<h2 id="7-2-">7.2 事务的实现</h2>
<p>事务隔离性由第6章讲述的锁来实现。原子性、一致性、持久性通过数据库的redolog 和 undo log 来完成。redo log称为重做日志，用来保证事务的原子性和持久性。undolog用来保证事务的一致性。</p>
<p>有的DBA或许会认为undo是redo 的逆过程，其实不然。redo 和 undo 的作用都可以视为是―种恢复操作，redo恢复提交事务修改的页操作，而undo回滚行记录到某个特定版本。因此两者记录的内容不同，redo通常是物理日志，记录的是页的物理修改操作。undo是逻辑日志，根据每行记录进行记录。</p>
<h3 id="7-2-1redo">7.2.1redo</h3>
<p>1.基本概念</p>
<p>重做日志用来实现事务的持久性，即事务ACID中的D。其由两部分组成:一是内存中的重做日志缓冲（redo log buffer)，其是易失的;二是重做日志文件(redo log file),其是持久的。</p>
<p>InnoDB是事务的存储引擎，其通过Force Log at Commit机制实现事务的持久性，即当事务提交(COMMIT）时，必须先将该事务的所有日志写入到重做日志文件进行持久化，待事务的COMMIT操作完成才算完成。这里的日志是指重做日志，在InnoDB存储引擎中，由两部分组成，即redo log 和 undo log。redo log用来保证事务的持久性，undo log用来帮助事务回滚及MVCC 的功能。redo log基本上都是顺序写的，在数据库运行时不需要对redo log 的文件进行读取操作。而undo log是需要进行随机读写的。</p>
<p>在 MySQL数据库中还有一种二进制日志（binlog)，其用来进行PoiKT-IN-TIME(PIT)的恢复及主从复制（Replication）环境的建立。从表面上看其和重做日志非常相似，都是记录了对于数据库操作的日志。然而，从本质上来看，两者有着非常大的不同。</p>
<p>首先，重做日志是在InnoDB存储引擎层产生，而二进制日志是在MySQL数据库的上层产生的，并且二进制日志不仅仅针对于InnoDB存储引擎，MySQL数据库中的任何存储引擎对于数据库的更改都会产生二进制日志。</p>
<p>其次，两种日志记录的内容形式不同。MySQL数据库上层的二进制日志是一种逻辑日志，其记录的是对应的SQL语句。而InnoDB存储引擎层面的重做日志是物理格式日志，其记录的是对于每个页的修改。</p>
<p>此外，两种日志记录写人磁盘的时间点不同，二进制日志只在事务提交完成后进行一次写人。而InnoDB存储引擎的重做日志在事务进行中不断地被写人，这表现为日志并不是随事务提交的顺序进行写入的。</p>
<p>2.log block</p>
<p>在InnoDB存储引擎中，重做日志都是以512字节进行存储的。这意味着重做日志缓存、重做日志文件都是以块（block)的方式进行保存的，称之为重做日志块(redolog block&gt;，每块的大小为512字节。
若一个页中产生的重做日志数量大于512字节，那么需要分割为多个重做日志块进行存储。此外，由于重做日志块的大小和磁盘扇区大小一样，都是512字节，因此重做日志的写入可以保证原子性,不需要doublewrite技术。</p>
<p>3.log group</p>
<p>log group为重做日志组，其中有多个重做日志文件。</p>
<p>InnoDB存储引擎运行过程中，log buffer根据一定的规则将内存中的log block刷新到磁盘。这个规则具体是:</p>
<ul>
<li>事务提交时</li>
<li>当log buffer中有一半的内存空间已经被使用时</li>
<li>log checkpoint时</li>
</ul>
<p>对于log block的写人追加（append)在redo log file的最后部分，当一个redo logfile被写满时，会接着写入下一个redo log file，其使用方式为round-robin。</p>
<p>虽然log block总是在redo log file的最后部分进行写人，有的读者可能以为对redolog file 的写入都是顺序的。其实不然，因为redo log file除了保存log buffer刷新到磁盘的log block，还保存了一些其他的信息，这些信息一共占用2KB大小，即每个redo logfile的前2KB的部分不保存log block的信息。</p>
<p>正因为保存了这些信息，就意味着对redo log file的写人并不是完全顺序的。因为其除了log block 的写人操作，还需要更新前2KB部分的信息，这些信息对于InnoDB存储引擎的恢复操作来说非常关键和重要。</p>
<p>4.重做日志格式</p>
<p>不同的数据库操作会有对应的重做日志格式。此外，由于InnoDB存储引擎的存储管理是基于页的，故其重做日志格式也是基于页的。</p>
<p>5.LSN</p>
<p>LSN是 Log Sequence Number的缩写，其代表的是日志序列号。在InnoDB存储引擎中，LSN占用8字节，并且单调递增。LSN表示的含义有:</p>
<ul>
<li>重做日志写入的总量</li>
<li>checkpoint的位置</li>
<li>页的版本</li>
</ul>
<p>LSN表示事务写入重做日志的字节的总量。例如当前重做日志的LSN为1 000，有一个事务T1写人了100字节的重做日志，那么LSN就变为了1100，若又有事务T2写入了200字节的重做日志，那么LSN就变为了1 300。可见LSN记录的是重做日志的总量，其单位为字节。</p>
<p>LSN不仅记录在重做日志中，还存在于每个页中。在每个页的头部，有一个值FIL_PAGE_LSN，记录了该页的LSN。在页中，LSN表示该页最后刷新时LSN的大小。因为重做日志记录的是每个页的日志，因此页中的LSN用来判断页是否需要进行恢复操作。例如，页P1的LSN为10 000，而数据库启动时，InnoDB检测到写人重做日志中的LSN为13 000，并且该事务已经提交，那么数据库需要进行恢复操作，将重做日志应用到P1页中。同样的，对于重做日志中LSN小于P1页的LSN，不需要进行重做,固勃P1页中的LSN表示页已经被刷新到该位置。</p>
<p>6.恢复</p>
<p>InnoDB存储引擎在启动时不管上次数据库运行时是否正常关闭，都会尝试进行恢复操作。因为重做日志记录的是物理日志，因此恢复的速度比逻辑日志，如二进制日志,要快很多。</p>
<p>由于checkpoint表示已经刷新到磁盘页上的LSN，因此在恢复过程中仅需恢复checkpoint开始的日志部分。对于图7-12中的例子，当数据库在checkpoint 的LSN 为10 000时发生宕机，恢复操作仅恢复LSN 10 000 ~13 000范围内的日志。</p>
<p>InnoDB存储引擎的重做日志是物理日志，因此其恢复速度较之二进制日志恢复快得多。例如对于INSERT操作，其记录的是每个页上的变化。对于下面的表:</p>
<pre><code class="lang-mysql">CREATETABLE t ( a INT,b INT,PRIMARY KEY(a),KEY(b) ) ;
</code></pre>
<p>若执行SQL语句:</p>
<pre><code class="lang-mysql">INSERT INTO t SELECT 1,2;
</code></pre>
<p>由于需要对聚集索引页和辅助索引页进行操作，其记录的重做日志大致为:</p>
<pre><code>page (2,3),offset 32, value 1,2 #聚集索引
page (2,4), offset 64, value 2 #辅助索引
</code></pre><p>可以看到记录的是页的物理修改操作，若插入涉及B＋树的split，可能会有更多的页需要记录日志。此外，由于重做日志是物理日志，因此其是幂等的。幂等的概念如下:</p>
<pre><code>f (f(x))=f (x)
</code></pre><p>有的 DBA或开发人员错误地认为只要将二进制日志的格式设置为ROW，那么二进制日志也是幂等的。这显然是错误的，举个简单的例子，INSERT 操作在二进制日志中就不是幂等的，重复执行可能会插人多条重复的记录。而上述 INSERT操作的重做日志是幂等的。</p>
<h3 id="7-2-2undo">7.2.2undo</h3>
<p>1.基本概念</p>
<p>重做日志记录了事务的行为，可以很好地通过其对页进行“重做”操作。但是事务有时还需要进行回滚操作，这时就需要undo。因此在对数据库进行修改时，InnoDB存储引擎不但会产生redo，还会产生一定量的undo。这样如果用户执行的事务或语句由于某种原因失败了，又或者用户用一条ROLLBACK语句请求回滚，就可以利用这些undo信息将数据回滚到修改之前的样子。</p>
<p>redo存放在重做日志文件中，与redo不同，undo存放在数据库内部的一个特殊段( segment）中，这个段称为undo段( undo segment)。undo段位于共享表空间内。</p>
<p>用户通常对undo有这样的误解:undo 用于将数据库物理地恢复到执行语句或事务之前的样子—-—但事实并非如此。undo是逻辑日志，因此只是将数据库逻辑地恢复到原来的样子。所有修改都被逻辑地取消了，但是数据结构和页本身在回滚之后可能大不相同。</p>
<p>比如，一个事务在修改当前一个页中某几条记录，同时还有别的事务在对同-个页中另几条记录进行修改。因此，不能将-个页回滚到事务开始的样子，因为这样会影响其他事务正在进行的工作。</p>
<p>例如，用户执行了一个INSERT 10W条记录的事务，这个事务会导致分配y个新的段，即表空间会增大。在用户执行ROLLBACK时，会将插入的事务进行回滚，但是表空间的大小并不会因此而收缩。因此，当InnoDB存储引擎回滚时，它实际上做的是与先前相反的工作。对于每个INSERT，InnoDB存储引擎会完成-一个DELETE﹔对于每个DELETE，InnoDB存储引擎会执行一个INSERT;对于每个UPDATE，InnoDB存储引擎会执行一个相反的 UPDATE，将修改前的行放回去。</p>
<p>除了回滚操作，undo 的另一个作用是MVCC，即在InnoDB存储引擎中MVCC的实现是通过undo来完成。当用户读取一行记录时，若该记录已经被其他事务占用，当前事务可以通过undo读取之前的行版本信息，以此实现非锁定读取。</p>
<p>最后也是最为重要的一点是，undo log 会产生redo log，也就是undo log 的产生会伴随着redo log 的产生，这是因为undo log 也需要持久性的保护。</p>
<h3 id="7-2-3-purge">7.2.3 purge</h3>
<p>delete和 update操作可能并不直接删除原有的数据。例如，对上一小节所产生的表t执行如下的SQL语句:</p>
<pre><code class="lang-mysql">DELETE FROM t WHERE a=1;
</code></pre>
<p>表t上列a有聚集索引，列b上有辅助索引。对于上述的delete操作，通过前面关于undo log 的介绍已经知道仅是将主键列等于1的记录delete flag 设置为1，记录并没有被删除，即记录还是存在于B+树中。其次，对辅助索引上 a等于1，b等于1的记录同样没有做任何处理，甚至没有产生undo log。而真正删除这行记录的操作其实被“延时”了，最终在purge操作中完成。</p>
<p>purge用于最终完成delete和 update操作。这样设计是因为InnoDB存储引擎支持MVCC，所以记录不能在事务提交时立即进行处理。这时其他事物可能正在引用这行,故InnoDB存储引擎需要保存记录之前的版本。而是否可以删除该条记录通过purge来进行判断。若该行记录已不被任何其他事务引用，那么就可以进行真正的deletc操作。可见，purge操作是清理之前的delete和 update操作，将上述操作“最终”完成。而实际执行的操作为delete操作，清理之前行记录的版本。</p>
<h3 id="7-2-4-group-commit">7.2.4 group commit</h3>
<p>若事务为非只读事务，则每次事务提交时需要进行一次fsync操作，以此保证重做日志都已经写入磁盘。当数据库发生宕机时，可以通过重做日志进行恢复。为了提高磁盘fsync的效率，当前数据库都提供了group commit的功能，即一次 fsync可以刷新确保多个事务日志被写入文件。对于InnoDB存储引擎来说，事务提交时会进行两个阶段的操作:</p>
<ol>
<li>修改内存中事务对应的信息，并且将日志写入重做日志缓冲。</li>
<li>调用fsync将确保日志都从重做日志缓冲写入磁盘。</li>
</ol>
<p>步骤2）相对步骤1）是一个较慢的过程，这是因为存储引擎需要与磁盘打交道。可以将多个事务的重做日志通过一次fsync刷新到磁盘，这样就大大地减少了磁盘的压力，从而提高了数据库的整体性能。对于写人或更新较为频繁的操作，group commit的效果尤为明显。</p>
<p>然而在 InnoDB1.2版本之前，在开启二进制日志后，InnoDB存储引擎的groupcommit功能会失效，从而导致性能的下降。并且在线环境多使用replication环境，因此二进制日志的选项基本都为开启状态，因此这个问题尤为显著。</p>
<p>导致这个问题的原因是在开启二进制日志后，为了保证存储引擎层中的事务和二进制日志的一致性，二者之间使用了两阶段事务，其步骤如下:</p>
<ol>
<li>当事务提交时InnoDB存储引擎进行prepare操作。</li>
<li>MySQL数据库上层写入二进制日志。</li>
<li><p>InnoDB存储引擎层将日志写入重做日志文件。</p>
<p> a）修改内存中事务对应的信息，并且将日志写人重做日志缓冲。</p>
<p> b）调用fsync将确保日志都从重做日志缓冲写入磁盘。</p>
</li>
</ol>
<p>一旦步骤2）中的操作完成，就确保了事务的提交，即使在执行步骤3）时数据库发生了宕机。此外需要注意的是，每个步骤都需要进行一次fsync操作才能保证上下两层数据的一致性。</p>
<p>然而，为什么需要保证MySQL数据库上层二进制日志的写入顺序和InnoDB层的事务提交顺序一致呢?这时因为备份及恢复的需要，例如通过工具 xtrabackup或者ibbackup进行备份，并用来建立replication，如图7-19所示。</p>
<p>pdf321页</p>
<p>可以看到若通过在线备份进行数据库恢复来重新建立replication，事务T1的数据会产生丢失。因此通过锁prepare_commit_mutex 以串行的方式来保证顺序性，然而这会使group commit无法生效，如图7-20所示。</p>
<p>这个问题最早在2010年的 MySQL数据库大会中提出，Facebook MySQL技术组，Percona公司都提出过解决方案。最后由MariaDB数据库的开发人员Kristian Nielsen完成了最终的“完美”解决方案。在这种情况下，不但MySQL数据库上层的云进制日志写入是group commit 的，InnoDB存储引擎层也是group commit的。此外还移除了原先的锁prepare_commit_mutex，从而大大提高了数据库的整体性。MySQL 5.6采用了类似的实现方式，并将其称为Binary Log Group Commit (BLGC)。</p>
<p>pdf322页</p>
<p>在MySQL数据库上层进行提交时首先按顺序将其放入一个队列中，队列中的第一个事务称为leader，其他事务称为follower，leader控制着follower的行为。BLGC的步骤分为以下三个阶段:</p>
<ol>
<li>Flush阶段，将每个事务的二进制日志写入内存中。</li>
<li>Sync阶段，将内存中的二进制日志刷新到磁盘，若队列中有多个事务，那么仅--次fsync操作就完成了二进制日志的写入，这就是BLGC。</li>
<li>Commit阶段，leader 根据顺序调用存储引擎层事务的提交，InnoDB存储引擎本就支持group commit，因此修复了原先由于锁prepare_commit_mutex导致groupcommit失效的问题。</li>
</ol>
<p>当有一组事务在进行Commit阶段时，其他新事物可以进行Flush阶段，从而使group commit不断生效。当然group commit的效果由队列中事务的数量决定，若每次队列中仅有-个事务，那么可能效果和之前差不多，甚至会更差。但当提交的事务越多时，group commit 的效果越明显，数据库性能的提升也就越大。</p>
<h2 id="7-3-">7.3 事务控制语句</h2>
<p>在MySQL命令行的默认设置下，事务都是自动提交(auto commit）的，即执行SQL语句后就会马上执行COMMIT操作。因此要显式地开启一个事务需使用命令BEGIN、START TRANSACTION，或者执行命令SET AUTOCOMMIT=0，禁用当前会话的自动提交。每个数据库厂商自动提交的设置都不相同，每个DBA或开发人员需要非常明白这一点，这对之后的SQL编程会有非凡的意义，因此用户不能以之前的经验来判断MySQL数据库的运行方式。在具体介绍其含义之前，先来看看用户可以使用哪些事务控制语句。</p>
<ul>
<li>START TRANSACTION | BEGIN:显式地开启一个事务。</li>
<li>COMMIT:要想使用这个语句的最简形式，只需发出COMMIT。也可以更详细一些，写为COMMIT WORK，不过这二者几乎是等价的。COMMIT会提交事务，并使得已对数据库做的所有修改成为永久性的。</li>
<li>ROLLBACK:要想使用这个语句的最简形式，只需发出ROLLBACK。同样地，也可以写为ROLLBACK WORK，但是二者几乎是等价的。回滚会结束用户的事务，并撤销正在进行的所有未提交的修改。</li>
<li>SAVEPOINT identifier : SAVEPOINT允许在事务中创建一个保存点，一个事务中可以有多个SAVEPOINT。</li>
<li>RELEASE SAVEPOINT identifier :删除一个事务的保存点，当没有一个保存点执行这句语句时，会抛出一个异常。</li>
<li>ROLLBACK TO[SAVEPOINT]identifier:这个语句与SAVEPOINT命令一起使用。可以把事务回滚到标记点，而不回滚在此标记点之前的任何工作。例如可以发出两条UPDATE语句，后面跟一个SAVEPOINT，然后又是两条DELETE语句。如果执行DELETE语句期间出现了某种异常情况，并且捕获到这个异常，同时发出了ROLLBACK TO SAVEPOINT命令，事务就会回滚到指定的SAVEPOINT，撤销DELETE完成的所有工作，而UPDATE语句完成的工作不受影响。</li>
<li>SET TRANSACTION:这个语句用来设置事务的隔离级别。InnoDB存储引擎提供的事务隔离级别有:READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ、SERIALIZABLE。</li>
</ul>
<p>START TRANSACTION、BEGIN语句都可以在 MySQL命令行下显式地开启云事务。但是在存储过程中，MySQL数据库的分析器会自动将BEGIN识别为BEGIN…END，因此在存储过程中只能使用START TRANSACTION语句来开启一个事务。</p>
<p>COMMIT和 COMMIT WORK语句基本是一致的，都是用来提交事务。不同之处在于COMMIT WORK用来控制事务结束后的行为是CHAIN还是RELEASE 的。如果是CHAIN方式，那么事务就变成了链事务。</p>
<p>用户可以通过参数completion_type来进行控制，该参数默认为0，表示没有任何操作。在这种设置下COMMIT和COMMIT WORK是完全等价的。当参数completion_type的值为1时，COMMIT WORK等同于COMMIT AND CHAIN，表示马上自动开启一个相同隔离级别的事务。</p>
<p>InnoDB存储引擎中的事务都是原子的，这说明下述两种情况:构成事务的每条语句都会提交（成为永久)，或者所有语句都回滚。这种保护还延伸到单个的语句。一条语句要么完全成功，要么完全回滚（注意，这里说的是语句回滚)。因此一条语句失败并抛出异常时，并不会导致先前已经执行的语句自动回滚。所有的执行都会得到保留，必须由用户自己来决定是否对其进行提交或回滚的操作。如:</p>
<p>可以看到，插入第二记录1时，因为重复的关系抛出了1062的错误，但是数据库并没有进行自动回滚，这时事务仍需要用户显式地运行COMMIT 或ROLLBACK命令。</p>
<p>另一个容易犯的错误是ROLLBACK TO SAVEPOINT，虽然有ROLLBACK，但其并不是真正地结束一个事务，因此即使执行了ROLLBACK TO SAVEPOINT，之后也需要显式地运行COMMIT或ROLLBACK命令。</p>
<p>可以看到，在上面的例子中，虽然在发生重复错误后用户通过ROLLBACKTO SAVEPOINT t2命令回滚到了保存点t2，但是事务此时没有结束。再运行命令ROLLBACK后，事务才会完整地回滚。这里再一次提醒，ROLLBACK TO SAVEPOINT命令并不真正地结束事务。</p>
<h2 id="7-4-sql-">7.4 隐式提交的 SQL语句</h2>
<p>以下这些SQL语句会产生一个隐式的提交操作，即执行完这些语句后，会有一个隐式的COMMIT操作。</p>
<ul>
<li>DDL语句:ALTER DATABASE...UPGRADE DATA DIRECTORY NAME,ALTER EVENT，ALTER PROCEDURE，ALTER TABLE，ALTER VIEW,CREATE DATABASE，CREATE EVENT，CREATE INDEX，CREATEPROCEDURE，CREATE TABLE，CREATE TRIGGER，CREATE VIEW,DROP DATABASE，DROP EVENT，DROP INDEX，DROP PROCEDURE,DROP TABLE，DROP TRIGGER，DROP VIEW，RENAME TABLE,TRUNCATE TABLE。</li>
<li>用来隐式地修改MySQL架构的操作:CREATE USER、DROP USER、GRANT、RENAME USER、REVOKE、SET PASSWORD。</li>
<li>管理语句:ANALYZE TABLE、CACHE INDEX、CHECK TABLE、LOAD INDEX
INTO CACHE、OPTIMIZE TABLE、REPAIR TABLE。</li>
</ul>
<p>注意&quot;我&quot;发现Microsoft SQL Server的数据库管理员或开发人员往往忽视对于DDL语句的隐式提交操作，因为在Microsoft sQL Server数据库中，即使是DDL也是可以回滚的。这和InnoDB存储引擎、Oracle这些数据库完全不同。</p>
<p>另外需要注意的是，TRUNCATE TABLE语句是DDL，因此虽然和对整张表执行DELETE的结果是一样的，但它是不能被回滚的（这又是和Microsoft SQL Server数据不同的地方)。</p>
<h2 id="7-5-">7.5 对于事务操作的统计</h2>
<p>由于InnoDB存储引擎是支持事务的，因此InnoDB存储引擎的应用需要在考虑每秒请求数（Question Per Second,QPS）的同时，应该关注每秒事务处理的能力(TransactionPer Second，TPS)。
计算TPS的方法是(com_commit+com_rollback)/time。但是利用这种方法进行计算的前提是:所有的事务必须都是显式提交的，如果存在隐式地提交和回滚（默认autocommit=1)，不会计算到com_commit和 com_rollback变量中。</p>
<h2 id="7-6-">7.6事务的隔离级别</h2>
<p>InnoDB存储引擎默认支持的隔离级别是REPEATABLE READ，但是与标准SQL不同的是，InnoDB存储引擎在REPEATABLE READ事务隔离级别下，使用Next-KeyLock锁的算法，因此避免幻读的产生。这与其他数据库系统（如Microsoft SQL Server数据库）是不同的。所以说，InnoDB存储引擎在默认的REPEATABLE READ的事务隔离级别下已经能完全保证事务的隔离性要求，即达到SQL标准的SERIALIZABLE隔离级别。</p>
<p>隔离级别越低，事务请求的锁越少或保持锁的时间就越短。这也是为什么大多数数据库系统默认的事务隔离级别是READ COMMITTED。
据了解，大部分的用户质疑SERIALIZABLE隔离级别带来的性能问题，但是根据Jim Gray在《Transaction Processing》一书中指出，两者的开销几乎是一样的，甚至SERIALIZABLE可能更优!!!因此在 InnoDB存储引擎中选择REPEATABLE READ的事务隔离级别并不会有任何性能的损失。同样地，即使使用READ COMMITTED的隔离级别，用户也不会得到性能的大幅度提升。</p>
<p>待定....</p>
<p>在MySQL 5.1版本之后，因为支持了ROW格式的二进制日志记录格式，避免了第二种情况的发生，所以可以放心使用READ COMMITTED 的事务隔离级别。但即使不使用READ COMMITTED 的事务隔离级别，也应该考虑将二进制日志的格式更换成ROw，因为这个格式记录的是行的变更，而不是简单的SQL语句，所以可以避免一些不同步现象的产生，进一步保证数据的同步。InnoDB存储引擎的创始人HeikkiTuuri也在http: ll bugs.mysql.com/bug.php?id=33210这个帖子中建议使用ROW格式的二进制日志。</p>
<h2 id="7-7-">7.7 分布式事务</h2>
<p>待定....</p>
<h2 id="7-8-">7.8 不好的事务习惯</h2>
<h3 id="7-8-1-">7.8.1在循环中提交</h3>
<p>开发人员非常喜欢在循环中进行事务的提交，下面是他们可能常写的一个存储过程:</p>
<pre><code class="lang-mysql">CREATE PROCEDURE load1 (count INT UNSIGNED)
BEGIN
DECLARE s INT UNSIGNED DEFAULT l;
DECLARE c CHAR (80)DEFAULT REPEAT (&#39;a&#39;,80) ;
WHILE s &lt;-count Do
INSERT INTO t1 SELECT NULL,c;
COMMIT;
SET s = s+1;END WHILE;
END;
</code></pre>
<p>其实，在上述的例子中，是否加上提交命令COMMIT并不关键。因为 InnoDB存储引擎默认为自动提交，所以在上述的存储过程中去掉COMMIT，结果其实是完全一样的。这也是另一个容易被开发人员忽视的问题:</p>
<pre><code class="lang-mysql">CREATE PROCEDURE load2 (count INTUNSIGNED)
BEGIN
DECLARE s INT UNSIGNED DEFAULT 1;
DECLARE c CHAR (80)DEFAULT REPEAT (&#39;a&#39;,80) ;
WHILE s &lt;= count Do
INSERTINTO t1 SELECT NULL,c;
SET s = s+1;
END WHILE;
END;
</code></pre>
<p>不论上面哪个存储过程都存在一个问题，当发生错误时，数据库会停留在一个未知的位置。例如，用户需要插入10 000条记录，但是在插入5000条时，发生了错误，这时前5000条记录已经存放在数据库中，那应该怎么处理呢?另--个问题是性能问题，上面两个存储过程都不会比下面的存储过程load3快，因为下面的存储过程将所有的INSERT 都放在一个事务中:</p>
<pre><code class="lang-mysql">CREATE PROCEDURE 1oad3 (count INT UNSIGNED)
BEGIN
DECLARE s INT UNSIGNED DEFAULT 1;
DECLARE cCHAR (80)DEFAULT REPEAT (&#39;a&#39;,80);
START TRANSACTION;
wHILE s &lt;=count Do
INSERT INTO t1 SELECT NULL,c;
SET s = s+1;
END WHILE;
COMMIT;
END;
</code></pre>
<p>显然，第三种方法要快得多!这是因为每一次提交都要写一次重做日志，存储过程load1和 load2实际写了10 000次重做日志文件，而对于存储过程 load3来说，实际只写了1次。可以对第二个存储过程load2的调用进行调整，同样可以达到存储过程 load3的性能，如:</p>
<pre><code class="lang-mysql">mysql&gt;BEGIN;
Query OK,0 rows affected (0.00 sec)

mysql&gt; CALL load2 (10000) ;
Query OK, 1 row affected (0.56 sec)

mysql&gt; COMMIT;
Query oK, 0 rows affected (0.03 sec)
</code></pre>
<p>大多数程序员会使用第一种或第二种方法，有人可能不知道InnoDB存储引擎自动提交的情况，另外有些人可能持有以下两种观点:首先，在他们曾经使用过的数据库中，对事务的要求总是尽快地进行释放，不能有长时间的事务﹔其次，他们可能担心存在Oracle数据库中由于没有足够undo产生的Snapshot Too Old的经典问题。MySQL 的InnoDB存储引擎没有上述两个问题，因此程序员不论从何种角度出发，都不应该在一个循环中反复进行提交操作，不论是显式的提交还是隐式的提交。</p>
<h3 id="7-8-2-">7.8.2使用自动提交</h3>
<p>自动提交并不是一个好的习惯，因为这会使初级DBA容易犯错，另外还可能使一些开发人员产生错误的理解，如我们在前一小节中提到的循环提交问题。</p>
<p>&quot;我&quot;认为，在编写应用程序开发时，最好把事务的控制权限交给开发人员，即在程序端进行事务的开始和结束。同时，开发人员必须了解自动提交可能带来的问题。我曾经见过很多开发人员没有意识到自动提交这个特性，等到出现错误时应用就会遇到大麻烦。</p>
<h3 id="7-8-3-">7.8.3 使用自动回滚</h3>
<p>InnoDB存储引擎支持通过定义一个HANDLER来进行自动事务的回滚操作，如在一个存储过程中发生了错误会自动对其进行回滚操作。因此我发现很多开发人员喜欢在应用程序的存储过程中使用自动回滚操作。</p>
<p>看起来用户可以得到运行是否准确的信息。但问题还没有最终解决，对于开发人员来说，重要的不仅是知道发生了错误，而是发生了什么样的错误。因此自动回滚存在这样的一个问题。</p>
<p>习惯使用自动回滚的人大多是以前使用Microsoft sQL Server数据库的开发人员。在Microsoft sQL Server数据库中，可以使用SET XABORT ON来自动回滚一个事务。但是Microsoft sQL Server数据库不仅会自动回滚当前的事务，还会抛出异常，开发人员可以捕获到这个异常。因此，Microsoft sQL Server数据库和MySQL数据库在这方面是有所不同的。</p>
<p>就像之前小节中所讲到的，对事务的BEGIN、COMMIT和 ROLLBACK操作应该交给程序端来完成，存储过程需要完成的只是一个逻辑的操作，即对逻辑进行封装。</p>
<p>在程序中控制事务的好处是，用户可以得知发生错误的原因。</p>
<h2 id="7-9-">7.9 长事务</h2>
<p>长事务(Long-Lived Transactions)，顾名思义，就是执行时间较长的事务。比如，对于银行系统的数据库，每过一个阶段可能需要更新对应账户的利息。如果对应账号的数量非常大，例如对有1亿用户的表account。</p>
<p>这时这个事务可能需要非常长的时间来完成。可能需要1个小时，也可能需要4、5个小时，这取决于数据库的硬件配置。DBA和开发人员本身能做的事情非常少。然而，由于事务ACID 的特性，这个操作被封装在一个事务中完成。这就产生了一个问题，在执行过程中，当数据库或操作系统、硬件等发生问题时，重新开始事务的代价变得不可接受。数据库需要回滚所有已经发生的变化，而这个过程可能比产生这些变化的时间还要长。因此，对于长事务的问题，有时可以通过转化为小批量(mini batch)的事务来进行处理。</p>
<p>通过批量处理小事务来完成大事务的逻辑。每完成一个小事务，将完成的结果存放在batchcontext表中，表示已完成批量事务的最大账号ID。若事务在运行过程中产生问题，需要重做事务，可以从这个已完成的最大事务ID继续进行批量的小事务，这样重新开启事务的代价就显得比较低，也更容易让用户接受。batchcontext 表的另外一个好处是，在长事务的执行过程中，用户可以知道现在大概已经执行到了哪个阶段。比如一共有1亿条的记录，现在表batchcontext中最大的账号ID为4000万，也就是说这个大事务大概完成了40%的工作。</p>
<p>这里还有一个小地方需要注意，在从表account中取得max_account_no时，人为地加上了一个共享锁，以保证在事务的处理过程中，没有其他的事务可以来更新表中的数据，这是有意义的，并且也是非常有必要的操作。</p>

          	</article>
        </div>


</html>

<script type="text/javascript" src="/toc/js/jquery-1.4.4.min.js"></script>
<script type="text/javascript" src="/toc/js/jquery.ztree.all-3.5.min.js"></script>
<script type="text/javascript" src="/toc/js/ztree_toc.js"></script>
<script type="text/javascript" src="/toc/js/toc_conf.js"></script>


<SCRIPT type="text/javascript" >
//<!--
$(document).ready(function(){
    var css_conf = eval(markdown_panel_style);
    $('#readme').css(css_conf)

    var conf = eval(jquery_ztree_toc_opts);
		$('#tree').ztree_toc(conf);
});
//-->
</SCRIPT>